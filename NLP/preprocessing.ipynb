{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2: Milestone I Natural Language Processing\n",
    "## Task 1. Basic Text Pre-processing\n",
    "#### Student Name: Kishore Sudhir\n",
    "#### Student ID: s3971501\n",
    "\n",
    "Date: 02/10/2023\n",
    "\n",
    "Version: 1.0\n",
    "\n",
    "Environment: Python 3 and Jupyter notebook\n",
    "\n",
    "Libraries used: please include all the libraries you used in your assignment, e.g.,:\n",
    "* nltk\n",
    "* numpy\n",
    "* sklearn\n",
    "* itertools\n",
    "\n",
    "## Introduction\n",
    "In this task, thorough text preprocessing was performed on a dataset comprising job advertisements, with a primary focus on the description field. A series of critical steps were followed, encompassing tokenization, converting to lowercase, eliminating short words, removing stopwords, and filtering out both infrequent and very frequent terms. The preprocessed job descriptions were then saved, and a vocabulary was created. These preprocessing actions are crucial for improving text data quality, making it suitable for diverse natural language processing tasks. The resultant refined data will prove invaluable for applications like text classification and information retrieval."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to import libraries as you need in this assessment, e.g.,\n",
    "import nltk\n",
    "import os\n",
    "import numpy as np \n",
    "from sklearn.datasets import load_files \n",
    "\n",
    "from nltk import RegexpTokenizer\n",
    "from nltk.probability import *\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from itertools import chain\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Examining and loading data\n",
    "- Examine the data folder, including the categories and job advertisment txt documents, etc. Explain your findings here, e.g., number of folders and format of txt files, etc.\n",
    "- Load the data into proper data structures and get it ready for processing.\n",
    "- Extract webIndex and description into proper data structures.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading data using load_files function from sklearn.datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading Data\n",
    "job_data = load_files(r\"data\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data stored will be similar to a dictionary (type), so we can read it's features or keys as shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'filenames', 'target_names', 'target', 'DESCR'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code to inspect the provided data file...\n",
    "job_data.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The keys are self explanatory, let's look at how the files are stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['data\\\\Accounting_Finance\\\\Job_00382.txt',\n",
       "       'data\\\\Accounting_Finance\\\\Job_00354.txt',\n",
       "       'data\\\\Healthcare_Nursing\\\\Job_00547.txt',\n",
       "       'data\\\\Accounting_Finance\\\\Job_00246.txt',\n",
       "       'data\\\\Healthcare_Nursing\\\\Job_00543.txt'], dtype='<U37')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_data['filenames'][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From above, it looks like data is categorisrd into folders base pn their industry or field of occupation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Accounting_Finance', 'Engineering', 'Healthcare_Nursing', 'Sales']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_data['target_names'] # shows the catregory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1, 2, 3}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(job_data['target']) # 4 types of numbers representing the above categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this data has five categories or classes\n",
    "\n",
    "Let's see which class matches to which class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accounting_Finance represents 0\n",
      "Engineering represents 1\n",
      "Healthcare_Nursing represents 2\n",
      "Sales represents 3\n"
     ]
    }
   ],
   "source": [
    "targets = set()\n",
    "for target in job_data['target']:\n",
    "    # Get the index of the target value\n",
    "    target_index = target\n",
    "\n",
    "    # Get the corresponding target name\n",
    "    target_name = job_data['target_names'][target_index]\n",
    "\n",
    "    # Create a tuple representing the pair\n",
    "    values = (target_name, target)\n",
    "\n",
    "    # Add the pair to the set of unique pairs\n",
    "    targets.add(values)\n",
    "\n",
    "sorted_targets = sorted(targets, key=lambda x: x[1])\n",
    "\n",
    "# Now, unique_pairs contains unique combinations of target_name and target\n",
    "for value in sorted_targets:\n",
    "    target_name, target = value\n",
    "    print(f\"{target_name} represents {target}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is expected result. Same order as results in prior cells "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's validate if extraction is done correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('data\\\\Accounting_Finance\\\\Job_00419.txt', 0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test\n",
    "\n",
    "ind = 7\n",
    "job_data['filenames'][ind], job_data['target'][ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "jdata, jindustry = job_data.data, job_data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(b'Title: Sales & Purchase Ledger Clerk  Maternity Cover\\nWebindex: 68684698\\nCompany: JK Personnel\\nDescription: Our client is looking to recruit an experienced Sales Purchase ledger clerk. You will be covering maternity over from February 2013  mid next year. The ideal candidate would be available immediately. DUTIES AND RESPONSIBILITIES (NOT LIMITED) Sales Ledger To input cheques/ bacs received onto Sage 200 accurately To reconcile remittances with actual receipts. To prepare the banking book To be responsible and ensure that all credit control has been done in a professional and timely manner. To send customer statements on a monthly basis Managing Aged Debtors Report Purchase Ledger To prepare the payment run, ensuring all invoices which are due will be processed and that there are no duplicates. To log all payments onto Sage 200 (cheques, bacs and chaps) To deal with account payable queries Managing Aged Creditors Report SKILLS REQUIREMENTS: 2 years experience Experience of systems and invoicing A good understanding of currencies Computer Literate in office, outlook, word and excel Sage 200 experience preferred, minimum Sage 50 Ability to work to tight deadlines without errors Good numeracy skills Good communication skills Well organised and efficient Good attention to detail This job was originally posted as www.totaljobs.com/JobSeeking/SalesPurchaseLedgerClerkMaternityCover_job****',\n",
       " 0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jdata[ind],jindustry[ind]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfect!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Pre-processing data\n",
    "Perform the required text pre-processing steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From preious examination, we can see that the data features (e.g. Title, Description, ...) are stored in as sentence. \n",
    "We only needed Description for this task and Title for future tasks, so `getFeature` function helps us to extract only required data form the new line seperated sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFeature(data,featureName):\n",
    "    \"\"\"\n",
    "    Function to extract a specific feature from a list of byte strings.\n",
    "\n",
    "    \"\"\"\n",
    "    features = []\n",
    "    for text in data:\n",
    "        feature = \"\"\n",
    "        # Convert the byte string to a regular string\n",
    "        text_decode = text.decode('utf-8')\n",
    "\n",
    "        # Split the text into lines\n",
    "        lines = text_decode.split('\\n')\n",
    "        for line in lines:\n",
    "            if line.startswith(featureName):\n",
    "                feature = line.split(featureName)[1].strip()\n",
    "                break  # Stop searching after finding the first description\n",
    "\n",
    "        features.append(feature)\n",
    "\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(': 68684698',\n",
       " 'Sales & Purchase Ledger Clerk  Maternity Cover',\n",
       " 'Our client is looking to recruit an experienced Sales Purchase ledger clerk. You will be covering maternity over from February 2013  mid next year. The ideal candidate would be available immediately. DUTIES AND RESPONSIBILITIES (NOT LIMITED) Sales Ledger To input cheques/ bacs received onto Sage 200 accurately To reconcile remittances with actual receipts. To prepare the banking book To be responsible and ensure that all credit control has been done in a professional and timely manner. To send customer statements on a monthly basis Managing Aged Debtors Report Purchase Ledger To prepare the payment run, ensuring all invoices which are due will be processed and that there are no duplicates. To log all payments onto Sage 200 (cheques, bacs and chaps) To deal with account payable queries Managing Aged Creditors Report SKILLS REQUIREMENTS: 2 years experience Experience of systems and invoicing A good understanding of currencies Computer Literate in office, outlook, word and excel Sage 200 experience preferred, minimum Sage 50 Ability to work to tight deadlines without errors Good numeracy skills Good communication skills Well organised and efficient Good attention to detail This job was originally posted as www.totaljobs.com/JobSeeking/SalesPurchaseLedgerClerkMaternityCover_job****',\n",
       " 0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descp = getFeature(jdata,\"Description:\") # Extract description\n",
    "windex = getFeature(jdata,\"Webindex\") # Extract web index\n",
    "title = getFeature(jdata,\"Title:\") # # Extract title, needed only for next task.\n",
    "windex[ind],title[ind],descp[ind], jindustry[ind] # visually validate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sales Purchase ledger clerk is job related to Accounting_Finance so target show as 0. Then so far so good :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenization is a crutial task, `tokenizeFeature` helps to tokenize given feature based on regex pattern `r\"[a-zA-Z]+(?:[-'][a-zA-Z]+)?\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization\n",
    "def tokenizeFeature(raw_feature):\n",
    "\n",
    "    \"\"\"\n",
    "    Function to tokenize raw feature based on the assignemnt requiremnts\n",
    "    \"\"\"\n",
    "    nl_feature = raw_feature.lower() # cover all words to lowercase\n",
    "    \n",
    "    # segament into sentences\n",
    "    features = sent_tokenize(nl_feature)\n",
    "    \n",
    "    # tokenize each sentence\n",
    "    pattern =  r\"[a-zA-Z]+(?:[-'][a-zA-Z]+)?\"\n",
    "    tokenizer = RegexpTokenizer(pattern) \n",
    "    token_lists = [tokenizer.tokenize(feat) for feat in features]\n",
    "    \n",
    "    # merge them into a list of tokens\n",
    "    tokenised_features = list(chain.from_iterable(token_lists))\n",
    "    return tokenised_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of tokenized descriptions\n",
    "tk_descriptions = [tokenizeFeature(d) for d in descp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['our',\n",
       " 'client',\n",
       " 'is',\n",
       " 'looking',\n",
       " 'to',\n",
       " 'recruit',\n",
       " 'an',\n",
       " 'experienced',\n",
       " 'sales',\n",
       " 'purchase',\n",
       " 'ledger',\n",
       " 'clerk',\n",
       " 'you',\n",
       " 'will',\n",
       " 'be',\n",
       " 'covering',\n",
       " 'maternity',\n",
       " 'over',\n",
       " 'from',\n",
       " 'february',\n",
       " 'mid',\n",
       " 'next',\n",
       " 'year',\n",
       " 'the',\n",
       " 'ideal',\n",
       " 'candidate',\n",
       " 'would',\n",
       " 'be',\n",
       " 'available',\n",
       " 'immediately',\n",
       " 'duties',\n",
       " 'and',\n",
       " 'responsibilities',\n",
       " 'not',\n",
       " 'limited',\n",
       " 'sales',\n",
       " 'ledger',\n",
       " 'to',\n",
       " 'input',\n",
       " 'cheques',\n",
       " 'bacs',\n",
       " 'received',\n",
       " 'onto',\n",
       " 'sage',\n",
       " 'accurately',\n",
       " 'to',\n",
       " 'reconcile',\n",
       " 'remittances',\n",
       " 'with',\n",
       " 'actual',\n",
       " 'receipts',\n",
       " 'to',\n",
       " 'prepare',\n",
       " 'the',\n",
       " 'banking',\n",
       " 'book',\n",
       " 'to',\n",
       " 'be',\n",
       " 'responsible',\n",
       " 'and',\n",
       " 'ensure',\n",
       " 'that',\n",
       " 'all',\n",
       " 'credit',\n",
       " 'control',\n",
       " 'has',\n",
       " 'been',\n",
       " 'done',\n",
       " 'in',\n",
       " 'a',\n",
       " 'professional',\n",
       " 'and',\n",
       " 'timely',\n",
       " 'manner',\n",
       " 'to',\n",
       " 'send',\n",
       " 'customer',\n",
       " 'statements',\n",
       " 'on',\n",
       " 'a',\n",
       " 'monthly',\n",
       " 'basis',\n",
       " 'managing',\n",
       " 'aged',\n",
       " 'debtors',\n",
       " 'report',\n",
       " 'purchase',\n",
       " 'ledger',\n",
       " 'to',\n",
       " 'prepare',\n",
       " 'the',\n",
       " 'payment',\n",
       " 'run',\n",
       " 'ensuring',\n",
       " 'all',\n",
       " 'invoices',\n",
       " 'which',\n",
       " 'are',\n",
       " 'due',\n",
       " 'will',\n",
       " 'be',\n",
       " 'processed',\n",
       " 'and',\n",
       " 'that',\n",
       " 'there',\n",
       " 'are',\n",
       " 'no',\n",
       " 'duplicates',\n",
       " 'to',\n",
       " 'log',\n",
       " 'all',\n",
       " 'payments',\n",
       " 'onto',\n",
       " 'sage',\n",
       " 'cheques',\n",
       " 'bacs',\n",
       " 'and',\n",
       " 'chaps',\n",
       " 'to',\n",
       " 'deal',\n",
       " 'with',\n",
       " 'account',\n",
       " 'payable',\n",
       " 'queries',\n",
       " 'managing',\n",
       " 'aged',\n",
       " 'creditors',\n",
       " 'report',\n",
       " 'skills',\n",
       " 'requirements',\n",
       " 'years',\n",
       " 'experience',\n",
       " 'experience',\n",
       " 'of',\n",
       " 'systems',\n",
       " 'and',\n",
       " 'invoicing',\n",
       " 'a',\n",
       " 'good',\n",
       " 'understanding',\n",
       " 'of',\n",
       " 'currencies',\n",
       " 'computer',\n",
       " 'literate',\n",
       " 'in',\n",
       " 'office',\n",
       " 'outlook',\n",
       " 'word',\n",
       " 'and',\n",
       " 'excel',\n",
       " 'sage',\n",
       " 'experience',\n",
       " 'preferred',\n",
       " 'minimum',\n",
       " 'sage',\n",
       " 'ability',\n",
       " 'to',\n",
       " 'work',\n",
       " 'to',\n",
       " 'tight',\n",
       " 'deadlines',\n",
       " 'without',\n",
       " 'errors',\n",
       " 'good',\n",
       " 'numeracy',\n",
       " 'skills',\n",
       " 'good',\n",
       " 'communication',\n",
       " 'skills',\n",
       " 'well',\n",
       " 'organised',\n",
       " 'and',\n",
       " 'efficient',\n",
       " 'good',\n",
       " 'attention',\n",
       " 'to',\n",
       " 'detail',\n",
       " 'this',\n",
       " 'job',\n",
       " 'was',\n",
       " 'originally',\n",
       " 'posted',\n",
       " 'as',\n",
       " 'www',\n",
       " 'totaljobs',\n",
       " 'com',\n",
       " 'jobseeking',\n",
       " 'salespurchaseledgerclerkmaternitycover',\n",
       " 'job']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tk_descriptions[ind]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Description was tokenized perfectly, below title is tokenized for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sales', 'purchase', 'ledger', 'clerk', 'maternity', 'cover']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenize text\n",
    "tk_title = [tokenizeFeature(t) for t in title]\n",
    "tk_title[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw description:\n",
      " Our client is looking to recruit an experienced Sales Purchase ledger clerk. You will be covering maternity over from February 2013  mid next year. The ideal candidate would be available immediately. DUTIES AND RESPONSIBILITIES (NOT LIMITED) Sales Ledger To input cheques/ bacs received onto Sage 200 accurately To reconcile remittances with actual receipts. To prepare the banking book To be responsible and ensure that all credit control has been done in a professional and timely manner. To send customer statements on a monthly basis Managing Aged Debtors Report Purchase Ledger To prepare the payment run, ensuring all invoices which are due will be processed and that there are no duplicates. To log all payments onto Sage 200 (cheques, bacs and chaps) To deal with account payable queries Managing Aged Creditors Report SKILLS REQUIREMENTS: 2 years experience Experience of systems and invoicing A good understanding of currencies Computer Literate in office, outlook, word and excel Sage 200 experience preferred, minimum Sage 50 Ability to work to tight deadlines without errors Good numeracy skills Good communication skills Well organised and efficient Good attention to detail This job was originally posted as www.totaljobs.com/JobSeeking/SalesPurchaseLedgerClerkMaternityCover_job**** \n",
      "\n",
      "Tokenized description:\n",
      " ['our', 'client', 'is', 'looking', 'to', 'recruit', 'an', 'experienced', 'sales', 'purchase', 'ledger', 'clerk', 'you', 'will', 'be', 'covering', 'maternity', 'over', 'from', 'february', 'mid', 'next', 'year', 'the', 'ideal', 'candidate', 'would', 'be', 'available', 'immediately', 'duties', 'and', 'responsibilities', 'not', 'limited', 'sales', 'ledger', 'to', 'input', 'cheques', 'bacs', 'received', 'onto', 'sage', 'accurately', 'to', 'reconcile', 'remittances', 'with', 'actual', 'receipts', 'to', 'prepare', 'the', 'banking', 'book', 'to', 'be', 'responsible', 'and', 'ensure', 'that', 'all', 'credit', 'control', 'has', 'been', 'done', 'in', 'a', 'professional', 'and', 'timely', 'manner', 'to', 'send', 'customer', 'statements', 'on', 'a', 'monthly', 'basis', 'managing', 'aged', 'debtors', 'report', 'purchase', 'ledger', 'to', 'prepare', 'the', 'payment', 'run', 'ensuring', 'all', 'invoices', 'which', 'are', 'due', 'will', 'be', 'processed', 'and', 'that', 'there', 'are', 'no', 'duplicates', 'to', 'log', 'all', 'payments', 'onto', 'sage', 'cheques', 'bacs', 'and', 'chaps', 'to', 'deal', 'with', 'account', 'payable', 'queries', 'managing', 'aged', 'creditors', 'report', 'skills', 'requirements', 'years', 'experience', 'experience', 'of', 'systems', 'and', 'invoicing', 'a', 'good', 'understanding', 'of', 'currencies', 'computer', 'literate', 'in', 'office', 'outlook', 'word', 'and', 'excel', 'sage', 'experience', 'preferred', 'minimum', 'sage', 'ability', 'to', 'work', 'to', 'tight', 'deadlines', 'without', 'errors', 'good', 'numeracy', 'skills', 'good', 'communication', 'skills', 'well', 'organised', 'and', 'efficient', 'good', 'attention', 'to', 'detail', 'this', 'job', 'was', 'originally', 'posted', 'as', 'www', 'totaljobs', 'com', 'jobseeking', 'salespurchaseledgerclerkmaternitycover', 'job']\n",
      "\n",
      "Raw Title:\n",
      " Sales & Purchase Ledger Clerk  Maternity Cover \n",
      "\n",
      "Tokenized Title:\n",
      " ['sales', 'purchase', 'ledger', 'clerk', 'maternity', 'cover']\n"
     ]
    }
   ],
   "source": [
    "# raw view vs tokenized view\n",
    "descp[ind], tk_descriptions[ind]\n",
    "print(\"Raw description:\\n\", descp[ind], \"\\n\\nTokenized description:\\n\", tk_descriptions[ind])\n",
    "print(\"\\nRaw Title:\\n\", title[ind], \"\\n\\nTokenized Title:\\n\", tk_title[ind])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This ensures that the tokenization process was executed accurately without any data mismatches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking stats, function is taken from week 7 lab exercise, with very little changes\n",
    "def stats_print(tk_descriptions):\n",
    "    \"\"\"\n",
    "    Function to print few stats of the given tokenized feature.\n",
    "\n",
    "    NOTE:\n",
    "    This function is taken from week 7 lab exercise, with very little (or no) changes\n",
    "    \"\"\"\n",
    "    words = list(chain.from_iterable(tk_descriptions))\n",
    "    vocab = set(words)\n",
    "    lexical_diversity = len(vocab)/len(words)\n",
    "    print(\"Vocabulary size: \",len(vocab))\n",
    "    print(\"Total number of tokens: \", len(words))\n",
    "    print(\"Lexical diversity: \", lexical_diversity)\n",
    "    print(\"Total number of description:\", len(tk_descriptions))\n",
    "    lens = [len(article) for article in tk_descriptions]\n",
    "    print(\"Average description length:\", np.mean(lens))\n",
    "    print(\"Maximun description length:\", np.max(lens))\n",
    "    print(\"Minimun description length:\", np.min(lens))\n",
    "    print(\"Standard deviation of description length:\", np.std(lens))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size:  9779\n",
      "Total number of tokens:  184038\n",
      "Lexical diversity:  0.05313576543974614\n",
      "Total number of description: 776\n",
      "Average description length: 237.16237113402062\n",
      "Maximun description length: 815\n",
      "Minimun description length: 1\n",
      "Standard deviation of description length: 128.22977695321202\n"
     ]
    }
   ],
   "source": [
    "stats_print(tk_descriptions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting from this point, tokenized text preprocessing adheres to the specifications outlined in Task 1: Basic Text Pre-processing (as per the assignment requirments)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33210"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove words with length less than 2\n",
    "\n",
    "dc_list = [[w for w in descp if len(w) <= 2 ] \\\n",
    "                      for descp in tk_descriptions]\n",
    "len(list(chain.from_iterable(dc_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtering out\n",
    "tk_descriptions = [[w for w in descp if len(w) >2] \\\n",
    "                      for descp in tk_descriptions]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtering out\n",
    "tk_title = [[w for w in descp if len(w) >2] \\\n",
    "                      for descp in tk_title]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop words\n",
    "\n",
    "stopwords_en = []\n",
    "with open('utils/stopwords_en.txt') as f:\n",
    "    stopwords_en = f.read().splitlines()\n",
    "    # stopwords_en = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "571"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stopwords_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "570"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwordSet = set(stopwords_en)\n",
    "len(stopwordSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = list(chain.from_iterable(tk_descriptions))\n",
    "vocab = set(words) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's deviate slightly from the specified requirements and check if there are any duplicated words in the `stopwords_en`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate stopwords: ['would']\n"
     ]
    }
   ],
   "source": [
    "duplicates = []\n",
    "seen = set()\n",
    "\n",
    "for word in stopwords_en:\n",
    "    if word in seen:\n",
    "        duplicates.append(word)\n",
    "    else:\n",
    "        seen.add(word)\n",
    "\n",
    "print(\"Duplicate stopwords:\", duplicates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below code removes stop word form `tk_descriptions`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size:  9192\n",
      "Total number of tokens:  104146\n",
      "Lexical diversity:  0.08826071092504753\n",
      "Total number of description: 776\n",
      "Average description length: 134.20876288659792\n",
      "Maximun description length: 482\n",
      "Minimun description length: 1\n",
      "Standard deviation of description length: 73.96986866017521\n"
     ]
    }
   ],
   "source": [
    "tk_descriptions = [[w for w in descp if w not in stopwordSet] for descp in tk_descriptions]\n",
    "stats_print(tk_descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = list(chain.from_iterable(tk_descriptions))\n",
    "vocab_after = set(words) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's exammine the removed words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 368 number of stop words.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['course',\n",
       " 'followed',\n",
       " 'comes',\n",
       " 'goes',\n",
       " 'alone',\n",
       " 'only',\n",
       " 'exactly',\n",
       " 'second',\n",
       " 'thus',\n",
       " 'else',\n",
       " 'seen',\n",
       " 'still',\n",
       " 'known',\n",
       " 'away',\n",
       " 'three',\n",
       " 'reasonably',\n",
       " 'much',\n",
       " 'nothing',\n",
       " 'becoming',\n",
       " 'her',\n",
       " 'throughout',\n",
       " 'why',\n",
       " \"what's\",\n",
       " 'ourselves',\n",
       " 'nine',\n",
       " 'itself',\n",
       " 'name',\n",
       " 'kept',\n",
       " 'without',\n",
       " 'want',\n",
       " 'say',\n",
       " 'available',\n",
       " 'know',\n",
       " 'look',\n",
       " 'likely',\n",
       " \"you'll\",\n",
       " 'believe',\n",
       " 'regarding',\n",
       " \"you're\",\n",
       " 'different',\n",
       " 'until',\n",
       " 'willing',\n",
       " \"you've\",\n",
       " 'uses',\n",
       " 'into',\n",
       " 'please',\n",
       " 'nobody',\n",
       " 'anyone',\n",
       " 'against',\n",
       " 'down',\n",
       " 'despite',\n",
       " 'entirely',\n",
       " 'indicated',\n",
       " 'non',\n",
       " 'might',\n",
       " 'and',\n",
       " 'least',\n",
       " 'while',\n",
       " 'outside',\n",
       " 'neither',\n",
       " 'seven',\n",
       " 'clearly',\n",
       " 'able',\n",
       " 'come',\n",
       " 'however',\n",
       " 'when',\n",
       " 'around',\n",
       " 'necessary',\n",
       " 'hopefully',\n",
       " 'upon',\n",
       " 'definitely',\n",
       " 'given',\n",
       " 'probably',\n",
       " 'those',\n",
       " 'later',\n",
       " 'self',\n",
       " 'beyond',\n",
       " 'unless',\n",
       " 'none',\n",
       " 'anything',\n",
       " 'some',\n",
       " 'here',\n",
       " 'already',\n",
       " 'across',\n",
       " 'since',\n",
       " 'gone',\n",
       " 'how',\n",
       " 'also',\n",
       " 'gives',\n",
       " 'needs',\n",
       " 'had',\n",
       " 'each',\n",
       " 'not',\n",
       " 'hence',\n",
       " 'though',\n",
       " \"it's\",\n",
       " 'like',\n",
       " 'namely',\n",
       " 'obviously',\n",
       " 'has',\n",
       " 'using',\n",
       " 'example',\n",
       " 'what',\n",
       " 'contains',\n",
       " 'was',\n",
       " 'which',\n",
       " 'certain',\n",
       " 'accordingly',\n",
       " 'changes',\n",
       " 'former',\n",
       " 'everything',\n",
       " 'amongst',\n",
       " 'near',\n",
       " 'are',\n",
       " 'once',\n",
       " \"he's\",\n",
       " 'through',\n",
       " 'causes',\n",
       " 'help',\n",
       " 'himself',\n",
       " 'because',\n",
       " 'various',\n",
       " 'that',\n",
       " 'four',\n",
       " 'possible',\n",
       " 'your',\n",
       " 'every',\n",
       " 'never',\n",
       " 'but',\n",
       " 'she',\n",
       " 'thereby',\n",
       " 'whenever',\n",
       " 'whole',\n",
       " 'soon',\n",
       " \"isn't\",\n",
       " 'very',\n",
       " 'been',\n",
       " 'best',\n",
       " 'overall',\n",
       " 'should',\n",
       " 'there',\n",
       " 'became',\n",
       " 'five',\n",
       " 'aside',\n",
       " 'themselves',\n",
       " 'tell',\n",
       " 'yours',\n",
       " 'anywhere',\n",
       " 'doing',\n",
       " 'were',\n",
       " 'these',\n",
       " 'the',\n",
       " 'other',\n",
       " 'after',\n",
       " 'within',\n",
       " 'com',\n",
       " 'less',\n",
       " 'take',\n",
       " 'sure',\n",
       " 'nearly',\n",
       " 'such',\n",
       " 'novel',\n",
       " 'apart',\n",
       " 'going',\n",
       " 'per',\n",
       " 'according',\n",
       " 'way',\n",
       " 'appropriate',\n",
       " 'currently',\n",
       " 'thank',\n",
       " 'having',\n",
       " 'under',\n",
       " 'our',\n",
       " 'specified',\n",
       " \"we'll\",\n",
       " 'perhaps',\n",
       " 'either',\n",
       " 'few',\n",
       " 'otherwise',\n",
       " 'off',\n",
       " 'everybody',\n",
       " 'yes',\n",
       " 'well',\n",
       " 'provides',\n",
       " 'something',\n",
       " 'being',\n",
       " 'containing',\n",
       " 'everyone',\n",
       " 'regards',\n",
       " 'one',\n",
       " 'gets',\n",
       " 'appreciate',\n",
       " 'use',\n",
       " 'along',\n",
       " 'this',\n",
       " 'whatever',\n",
       " \"c's\",\n",
       " 'last',\n",
       " 'immediate',\n",
       " 'normally',\n",
       " 'cannot',\n",
       " \"that's\",\n",
       " 'somebody',\n",
       " 'far',\n",
       " 'thorough',\n",
       " 'secondly',\n",
       " 'keep',\n",
       " 'could',\n",
       " 'between',\n",
       " 'old',\n",
       " 'ours',\n",
       " 'done',\n",
       " 'does',\n",
       " 'described',\n",
       " 'behind',\n",
       " 'associated',\n",
       " 'quite',\n",
       " 'enough',\n",
       " 'right',\n",
       " 'who',\n",
       " 'allow',\n",
       " 'would',\n",
       " 'really',\n",
       " 'maybe',\n",
       " 'useful',\n",
       " 'others',\n",
       " 'too',\n",
       " 'even',\n",
       " 'from',\n",
       " 'unfortunately',\n",
       " \"haven't\",\n",
       " 'hereby',\n",
       " \"they're\",\n",
       " 'took',\n",
       " 'value',\n",
       " 'follows',\n",
       " 'says',\n",
       " 'may',\n",
       " 'welcome',\n",
       " 'further',\n",
       " 'wherever',\n",
       " 'yet',\n",
       " 'ever',\n",
       " 'need',\n",
       " 'always',\n",
       " 'for',\n",
       " 'mainly',\n",
       " 'considering',\n",
       " 'plus',\n",
       " 'etc',\n",
       " 'especially',\n",
       " 'together',\n",
       " 'following',\n",
       " 'via',\n",
       " 'can',\n",
       " 'got',\n",
       " 'elsewhere',\n",
       " 'little',\n",
       " 'next',\n",
       " \"let's\",\n",
       " 'nor',\n",
       " 'sub',\n",
       " 'specifying',\n",
       " 'better',\n",
       " 'getting',\n",
       " 'furthermore',\n",
       " 'many',\n",
       " 'allows',\n",
       " 'during',\n",
       " 'become',\n",
       " \"we've\",\n",
       " 'ltd',\n",
       " 'looks',\n",
       " 'ask',\n",
       " 'out',\n",
       " 'toward',\n",
       " \"we're\",\n",
       " 'both',\n",
       " 'their',\n",
       " 'mean',\n",
       " 'you',\n",
       " 'now',\n",
       " 'yourself',\n",
       " 'thanks',\n",
       " 'its',\n",
       " \"here's\",\n",
       " 'think',\n",
       " 'consider',\n",
       " 'rather',\n",
       " 'own',\n",
       " 'six',\n",
       " 'then',\n",
       " 'wish',\n",
       " 'although',\n",
       " 'happens',\n",
       " 'inc',\n",
       " 'thoroughly',\n",
       " 'usually',\n",
       " 'herself',\n",
       " 'among',\n",
       " 'particular',\n",
       " 'downwards',\n",
       " 'with',\n",
       " 'wants',\n",
       " 'than',\n",
       " 'serious',\n",
       " 'about',\n",
       " 'first',\n",
       " 'two',\n",
       " 'twice',\n",
       " 'more',\n",
       " 'brief',\n",
       " 'somewhere',\n",
       " \"don't\",\n",
       " 'most',\n",
       " 'must',\n",
       " 'all',\n",
       " 'whose',\n",
       " 'below',\n",
       " 'sometimes',\n",
       " 'cause',\n",
       " 'new',\n",
       " 'just',\n",
       " 'concerning',\n",
       " 'taken',\n",
       " 'zero',\n",
       " 'third',\n",
       " 'everywhere',\n",
       " 'his',\n",
       " 'formerly',\n",
       " 'almost',\n",
       " 'where',\n",
       " 'mostly',\n",
       " 'any',\n",
       " 'above',\n",
       " 'let',\n",
       " 'looking',\n",
       " 'placed',\n",
       " 'certainly',\n",
       " 'same',\n",
       " 'used',\n",
       " 'whether',\n",
       " 'onto',\n",
       " 'shall',\n",
       " 'have',\n",
       " 'therefore',\n",
       " 'particularly',\n",
       " 'sent',\n",
       " 'towards',\n",
       " 'respectively',\n",
       " 'get',\n",
       " 'try',\n",
       " 'regardless',\n",
       " 'again',\n",
       " 'over',\n",
       " 'another',\n",
       " 'someone',\n",
       " \"hasn't\",\n",
       " 'truly',\n",
       " 'see',\n",
       " 'specify',\n",
       " 'often',\n",
       " 'them',\n",
       " 'several',\n",
       " 'will',\n",
       " 'whom',\n",
       " 'before',\n",
       " 'they']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "removed = list(vocab - vocab_after)  # words before - words after\n",
    "print(f\"Removed {len(removed)} number of stop words.\")\n",
    "removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(104146, 9192)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words),len(vocab_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking stop words for title\n",
    "titlewords  = list(chain.from_iterable(tk_title))\n",
    "title_vocab_before = set(titlewords) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "tk_title = [[w for w in title if w not in stopwordSet] for title in tk_title]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 368 number of stop words.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['course',\n",
       " 'followed',\n",
       " 'comes',\n",
       " 'goes',\n",
       " 'alone',\n",
       " 'only',\n",
       " 'exactly',\n",
       " 'second',\n",
       " 'thus',\n",
       " 'else',\n",
       " 'seen',\n",
       " 'still',\n",
       " 'known',\n",
       " 'away',\n",
       " 'three',\n",
       " 'reasonably',\n",
       " 'much',\n",
       " 'nothing',\n",
       " 'becoming',\n",
       " 'her',\n",
       " 'throughout',\n",
       " 'why',\n",
       " \"what's\",\n",
       " 'ourselves',\n",
       " 'nine',\n",
       " 'itself',\n",
       " 'name',\n",
       " 'kept',\n",
       " 'without',\n",
       " 'want',\n",
       " 'say',\n",
       " 'available',\n",
       " 'know',\n",
       " 'look',\n",
       " 'likely',\n",
       " \"you'll\",\n",
       " 'believe',\n",
       " 'regarding',\n",
       " \"you're\",\n",
       " 'different',\n",
       " 'until',\n",
       " 'willing',\n",
       " \"you've\",\n",
       " 'uses',\n",
       " 'into',\n",
       " 'please',\n",
       " 'nobody',\n",
       " 'anyone',\n",
       " 'against',\n",
       " 'down',\n",
       " 'despite',\n",
       " 'entirely',\n",
       " 'indicated',\n",
       " 'non',\n",
       " 'might',\n",
       " 'and',\n",
       " 'least',\n",
       " 'while',\n",
       " 'outside',\n",
       " 'neither',\n",
       " 'seven',\n",
       " 'clearly',\n",
       " 'able',\n",
       " 'come',\n",
       " 'however',\n",
       " 'when',\n",
       " 'around',\n",
       " 'necessary',\n",
       " 'hopefully',\n",
       " 'upon',\n",
       " 'definitely',\n",
       " 'given',\n",
       " 'probably',\n",
       " 'those',\n",
       " 'later',\n",
       " 'self',\n",
       " 'beyond',\n",
       " 'unless',\n",
       " 'none',\n",
       " 'anything',\n",
       " 'some',\n",
       " 'here',\n",
       " 'already',\n",
       " 'across',\n",
       " 'since',\n",
       " 'gone',\n",
       " 'how',\n",
       " 'also',\n",
       " 'gives',\n",
       " 'needs',\n",
       " 'had',\n",
       " 'each',\n",
       " 'not',\n",
       " 'hence',\n",
       " 'though',\n",
       " \"it's\",\n",
       " 'like',\n",
       " 'namely',\n",
       " 'obviously',\n",
       " 'has',\n",
       " 'using',\n",
       " 'example',\n",
       " 'what',\n",
       " 'contains',\n",
       " 'was',\n",
       " 'which',\n",
       " 'certain',\n",
       " 'accordingly',\n",
       " 'changes',\n",
       " 'former',\n",
       " 'everything',\n",
       " 'amongst',\n",
       " 'near',\n",
       " 'are',\n",
       " 'once',\n",
       " \"he's\",\n",
       " 'through',\n",
       " 'causes',\n",
       " 'help',\n",
       " 'himself',\n",
       " 'because',\n",
       " 'various',\n",
       " 'that',\n",
       " 'four',\n",
       " 'possible',\n",
       " 'your',\n",
       " 'every',\n",
       " 'never',\n",
       " 'but',\n",
       " 'she',\n",
       " 'thereby',\n",
       " 'whenever',\n",
       " 'whole',\n",
       " 'soon',\n",
       " \"isn't\",\n",
       " 'very',\n",
       " 'been',\n",
       " 'best',\n",
       " 'overall',\n",
       " 'should',\n",
       " 'there',\n",
       " 'became',\n",
       " 'five',\n",
       " 'aside',\n",
       " 'themselves',\n",
       " 'tell',\n",
       " 'yours',\n",
       " 'anywhere',\n",
       " 'doing',\n",
       " 'were',\n",
       " 'these',\n",
       " 'the',\n",
       " 'other',\n",
       " 'after',\n",
       " 'within',\n",
       " 'com',\n",
       " 'less',\n",
       " 'take',\n",
       " 'sure',\n",
       " 'nearly',\n",
       " 'such',\n",
       " 'novel',\n",
       " 'apart',\n",
       " 'going',\n",
       " 'per',\n",
       " 'according',\n",
       " 'way',\n",
       " 'appropriate',\n",
       " 'currently',\n",
       " 'thank',\n",
       " 'having',\n",
       " 'under',\n",
       " 'our',\n",
       " 'specified',\n",
       " \"we'll\",\n",
       " 'perhaps',\n",
       " 'either',\n",
       " 'few',\n",
       " 'otherwise',\n",
       " 'off',\n",
       " 'everybody',\n",
       " 'yes',\n",
       " 'well',\n",
       " 'provides',\n",
       " 'something',\n",
       " 'being',\n",
       " 'containing',\n",
       " 'everyone',\n",
       " 'regards',\n",
       " 'one',\n",
       " 'gets',\n",
       " 'appreciate',\n",
       " 'use',\n",
       " 'along',\n",
       " 'this',\n",
       " 'whatever',\n",
       " \"c's\",\n",
       " 'last',\n",
       " 'immediate',\n",
       " 'normally',\n",
       " 'cannot',\n",
       " \"that's\",\n",
       " 'somebody',\n",
       " 'far',\n",
       " 'thorough',\n",
       " 'secondly',\n",
       " 'keep',\n",
       " 'could',\n",
       " 'between',\n",
       " 'old',\n",
       " 'ours',\n",
       " 'done',\n",
       " 'does',\n",
       " 'described',\n",
       " 'behind',\n",
       " 'associated',\n",
       " 'quite',\n",
       " 'enough',\n",
       " 'right',\n",
       " 'who',\n",
       " 'allow',\n",
       " 'would',\n",
       " 'really',\n",
       " 'maybe',\n",
       " 'useful',\n",
       " 'others',\n",
       " 'too',\n",
       " 'even',\n",
       " 'from',\n",
       " 'unfortunately',\n",
       " \"haven't\",\n",
       " 'hereby',\n",
       " \"they're\",\n",
       " 'took',\n",
       " 'value',\n",
       " 'follows',\n",
       " 'says',\n",
       " 'may',\n",
       " 'welcome',\n",
       " 'further',\n",
       " 'wherever',\n",
       " 'yet',\n",
       " 'ever',\n",
       " 'need',\n",
       " 'always',\n",
       " 'for',\n",
       " 'mainly',\n",
       " 'considering',\n",
       " 'plus',\n",
       " 'etc',\n",
       " 'especially',\n",
       " 'together',\n",
       " 'following',\n",
       " 'via',\n",
       " 'can',\n",
       " 'got',\n",
       " 'elsewhere',\n",
       " 'little',\n",
       " 'next',\n",
       " \"let's\",\n",
       " 'nor',\n",
       " 'sub',\n",
       " 'specifying',\n",
       " 'better',\n",
       " 'getting',\n",
       " 'furthermore',\n",
       " 'many',\n",
       " 'allows',\n",
       " 'during',\n",
       " 'become',\n",
       " \"we've\",\n",
       " 'ltd',\n",
       " 'looks',\n",
       " 'ask',\n",
       " 'out',\n",
       " 'toward',\n",
       " \"we're\",\n",
       " 'both',\n",
       " 'their',\n",
       " 'mean',\n",
       " 'you',\n",
       " 'now',\n",
       " 'yourself',\n",
       " 'thanks',\n",
       " 'its',\n",
       " \"here's\",\n",
       " 'think',\n",
       " 'consider',\n",
       " 'rather',\n",
       " 'own',\n",
       " 'six',\n",
       " 'then',\n",
       " 'wish',\n",
       " 'although',\n",
       " 'happens',\n",
       " 'inc',\n",
       " 'thoroughly',\n",
       " 'usually',\n",
       " 'herself',\n",
       " 'among',\n",
       " 'particular',\n",
       " 'downwards',\n",
       " 'with',\n",
       " 'wants',\n",
       " 'than',\n",
       " 'serious',\n",
       " 'about',\n",
       " 'first',\n",
       " 'two',\n",
       " 'twice',\n",
       " 'more',\n",
       " 'brief',\n",
       " 'somewhere',\n",
       " \"don't\",\n",
       " 'most',\n",
       " 'must',\n",
       " 'all',\n",
       " 'whose',\n",
       " 'below',\n",
       " 'sometimes',\n",
       " 'cause',\n",
       " 'new',\n",
       " 'just',\n",
       " 'concerning',\n",
       " 'taken',\n",
       " 'zero',\n",
       " 'third',\n",
       " 'everywhere',\n",
       " 'his',\n",
       " 'formerly',\n",
       " 'almost',\n",
       " 'where',\n",
       " 'mostly',\n",
       " 'any',\n",
       " 'above',\n",
       " 'let',\n",
       " 'looking',\n",
       " 'placed',\n",
       " 'certainly',\n",
       " 'same',\n",
       " 'used',\n",
       " 'whether',\n",
       " 'onto',\n",
       " 'shall',\n",
       " 'have',\n",
       " 'therefore',\n",
       " 'particularly',\n",
       " 'sent',\n",
       " 'towards',\n",
       " 'respectively',\n",
       " 'get',\n",
       " 'try',\n",
       " 'regardless',\n",
       " 'again',\n",
       " 'over',\n",
       " 'another',\n",
       " 'someone',\n",
       " \"hasn't\",\n",
       " 'truly',\n",
       " 'see',\n",
       " 'specify',\n",
       " 'often',\n",
       " 'them',\n",
       " 'several',\n",
       " 'will',\n",
       " 'whom',\n",
       " 'before',\n",
       " 'they']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titlewords  = list(chain.from_iterable(tk_title))\n",
    "title_vocab_before = set(titlewords) \n",
    "removed_title = list(title_vocab_before - title_vocab_before)  # words before - words after\n",
    "print(f\"Removed {len(removed)} number of stop words.\")\n",
    "removed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre processing below are only done to `Description`, not for `Title` as it might not be appropriate to remove them in title based on stats \n",
    "\n",
    "Even, Luke Gallagher mentioned this in discussion forum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# term frequency\n",
    "term_freq = FreqDist(words) # description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('experience', 1260),\n",
       " ('sales', 1023),\n",
       " ('role', 941),\n",
       " ('work', 842),\n",
       " ('business', 823)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "term_freq.most_common(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'kilmarnock',\n",
       " \"ireland's\",\n",
       " 'flm',\n",
       " 'imaginative',\n",
       " 'conversational',\n",
       " 'cascaded',\n",
       " 'stone',\n",
       " 'nmcresponsible',\n",
       " 'payingin',\n",
       " 'eng',\n",
       " 'surpassing',\n",
       " 'biopharma',\n",
       " 'financeanalyst',\n",
       " 'homeholly',\n",
       " 'applythis',\n",
       " 'discretionary',\n",
       " 'hcv',\n",
       " 'equate',\n",
       " 'remittances',\n",
       " 'apqp',\n",
       " 'calendar',\n",
       " 'couriers',\n",
       " 'gyfrinachol',\n",
       " 'decline',\n",
       " 'discloser',\n",
       " 'sutherland',\n",
       " 'entities',\n",
       " 'mct',\n",
       " 'puts',\n",
       " 'genetics',\n",
       " 'determines',\n",
       " 'testandvalidationengineer',\n",
       " 'salesexecutivemeetingseventsaberdeen',\n",
       " 'urgency',\n",
       " 'underwrite',\n",
       " 'rfj',\n",
       " 'overcoming',\n",
       " 'dysphagia',\n",
       " 'xsd',\n",
       " 'illnesses',\n",
       " 'shortlist',\n",
       " 'passing',\n",
       " 'terry',\n",
       " 'multinationals',\n",
       " 'implicitly',\n",
       " 'reacting',\n",
       " 'preventable',\n",
       " 'doubled',\n",
       " 'netbios',\n",
       " 'langley',\n",
       " 'mrcpsych',\n",
       " 'ruane',\n",
       " 'absences',\n",
       " 'mencap',\n",
       " 'leinster',\n",
       " 'liamzest',\n",
       " 'ranalyst',\n",
       " 'legally',\n",
       " 'pbo',\n",
       " 'gilchrist',\n",
       " 'eating',\n",
       " 'governments',\n",
       " 'commencement',\n",
       " 'staines',\n",
       " 'painting',\n",
       " 'wwf',\n",
       " 'responsibliities',\n",
       " 'referencesthis',\n",
       " 'morris',\n",
       " 'leatherhead',\n",
       " 'chwilio',\n",
       " 'celebrated',\n",
       " 'competitively',\n",
       " 'appreciated',\n",
       " 'targetorientated',\n",
       " 'patented',\n",
       " 'mnos',\n",
       " 'fmeca',\n",
       " 'quo',\n",
       " 'ignore',\n",
       " 'destruction',\n",
       " 'responds',\n",
       " 'rapportyou',\n",
       " 'unmatched',\n",
       " 'precious',\n",
       " 'rose',\n",
       " 'coleraine',\n",
       " 'hcr',\n",
       " 'amada',\n",
       " 'basisthe',\n",
       " 'highstreet',\n",
       " 'wedi',\n",
       " 'malfunctions',\n",
       " 'glorious',\n",
       " 'mlse',\n",
       " 'disappointed',\n",
       " 'ssc',\n",
       " 'netting',\n",
       " 'mexico',\n",
       " 'ceremonies',\n",
       " 'pen',\n",
       " 'sdlc',\n",
       " 'embraces',\n",
       " 'establishged',\n",
       " 'pontefract',\n",
       " 'europeansalesmanager',\n",
       " 'raglenni',\n",
       " 'souths',\n",
       " 'justified',\n",
       " 'aelodau',\n",
       " 'coherent',\n",
       " 'feasibility',\n",
       " 'sharedservice',\n",
       " 'salesexecinternal',\n",
       " 'antennas',\n",
       " 'disruption',\n",
       " 'megabrands',\n",
       " 'lcr',\n",
       " 'hanfodol',\n",
       " 'gardening',\n",
       " 'multidiscipline',\n",
       " 'aligning',\n",
       " 'healthsalary',\n",
       " 'subcontractledgerclerkfulltimepermimmediatestart',\n",
       " 'remits',\n",
       " 'interactions',\n",
       " 'wardday',\n",
       " 'instruction',\n",
       " 'dentist',\n",
       " 'bushings',\n",
       " 'proving',\n",
       " 'telematic',\n",
       " 'oxley',\n",
       " 'treasuryamct',\n",
       " 'landscape',\n",
       " 'accountancyapprentice',\n",
       " 'mortgages',\n",
       " 'subteams',\n",
       " 'renew',\n",
       " 'bennett',\n",
       " 'mechancial',\n",
       " 'promenade',\n",
       " 'takeoffs',\n",
       " 'borrowers',\n",
       " 'deck',\n",
       " 'nebosh',\n",
       " 'streak',\n",
       " 'winches',\n",
       " 'sefydlog',\n",
       " \"hospital's\",\n",
       " 'mins',\n",
       " 'football',\n",
       " 'ranked',\n",
       " 'misra',\n",
       " 'nonverbal',\n",
       " 'collar',\n",
       " 'reclaimable',\n",
       " 'highspec',\n",
       " 'denture',\n",
       " 'multitier',\n",
       " 'arrive',\n",
       " 'interactive',\n",
       " 'exhibited',\n",
       " 'shaving',\n",
       " 'churchdown',\n",
       " 'shaz',\n",
       " 'wycombe',\n",
       " \"nation's\",\n",
       " 'floorcoverings',\n",
       " 'pressures',\n",
       " 'draftsperson',\n",
       " 'evans',\n",
       " 'monmouth',\n",
       " 'postcloses',\n",
       " 'wastage',\n",
       " 'manpower',\n",
       " 'reflexology',\n",
       " 'relevantexperience',\n",
       " 'fancy',\n",
       " 'curtis',\n",
       " 'ranks',\n",
       " 'rgnqualified',\n",
       " 'struggled',\n",
       " 'revise',\n",
       " 'customs',\n",
       " 'nic',\n",
       " 'hamble',\n",
       " 'nonstandard',\n",
       " 'letchworth',\n",
       " 'managersector',\n",
       " 'inhibit',\n",
       " 'cdp',\n",
       " 'irregularity',\n",
       " 'ifss',\n",
       " 'tech',\n",
       " 'applytodaystarttomorrownewsalesfor',\n",
       " 'reinsurance',\n",
       " 'compliment',\n",
       " 'remainder',\n",
       " 'eager',\n",
       " 'recreations',\n",
       " 'cramlington',\n",
       " 'wagstaff',\n",
       " 'garyitscity',\n",
       " 'kate',\n",
       " 'acknowledged',\n",
       " 'steering',\n",
       " 'zuken',\n",
       " 'indication',\n",
       " 'cfa',\n",
       " 'coordinated',\n",
       " 'rigorous',\n",
       " 'distressed',\n",
       " 'deadline',\n",
       " 'shiftmanagerfmcg',\n",
       " 'cluster',\n",
       " 'dietetic',\n",
       " 'subsidized',\n",
       " 'postoperative',\n",
       " 'remunerated',\n",
       " 'dudley',\n",
       " 'inverness',\n",
       " 'mcgougan',\n",
       " 'allen',\n",
       " 'staffnet',\n",
       " 'bushing',\n",
       " 'netherton',\n",
       " 'finniganpopulusconsultants',\n",
       " 'mds',\n",
       " 'los',\n",
       " 'kildare',\n",
       " 'bullself',\n",
       " 'nmcuk',\n",
       " 'costings',\n",
       " 'quang',\n",
       " 'negotiations',\n",
       " 'nestle',\n",
       " \"cv's\",\n",
       " 'arinc',\n",
       " 'rheoli',\n",
       " 'aga',\n",
       " 'prize',\n",
       " 'hymgynghorwyr',\n",
       " 'iva',\n",
       " 'digestion',\n",
       " 'embarks',\n",
       " 'opportunties',\n",
       " 'williams',\n",
       " 'poultry',\n",
       " 'motherwell',\n",
       " 'constructors',\n",
       " 'introduce',\n",
       " 'practiceif',\n",
       " 'tvs',\n",
       " 'pathways',\n",
       " 'discharge',\n",
       " 'managementmaintain',\n",
       " 'islington',\n",
       " 'validity',\n",
       " 'taxassistantmanager',\n",
       " 'showerhead',\n",
       " 'alerts',\n",
       " 'bpt',\n",
       " 'logbooks',\n",
       " 'qualityengineertechnician',\n",
       " 'geared',\n",
       " 'supermarket',\n",
       " 'leonardo',\n",
       " 'dotted',\n",
       " 'thatcham',\n",
       " 'ontargetearnings',\n",
       " 'seminars',\n",
       " 'serviceengineerhighpressuresystems',\n",
       " 'shipped',\n",
       " 'shortlisting',\n",
       " 'requirred',\n",
       " 'reimbursement',\n",
       " 'doug',\n",
       " 'torque',\n",
       " 'backselling',\n",
       " 'scarborough',\n",
       " 'prisons',\n",
       " 'unwavering',\n",
       " 'gamp',\n",
       " 'hanner',\n",
       " 'formalised',\n",
       " 'trafodaeth',\n",
       " 'courteous',\n",
       " 'aftercare',\n",
       " 'bognor',\n",
       " 'anaerobic',\n",
       " 'holidaysbms',\n",
       " 'downloads',\n",
       " 'kva',\n",
       " 'cscs',\n",
       " 'cancellation',\n",
       " 'commentaries',\n",
       " 'dealt',\n",
       " 'flexsa',\n",
       " 'theukandsouth',\n",
       " 'seasoned',\n",
       " 'fmhead',\n",
       " 'fieldsalesexecutivederby',\n",
       " 'lcwallacehind',\n",
       " 'innovators',\n",
       " 'zouch',\n",
       " 'icobs',\n",
       " 'farringdon',\n",
       " 'greeneking',\n",
       " 'senioraccountexecutivesales',\n",
       " 'suffered',\n",
       " 'prestigiouslondoncontracts',\n",
       " 'prohibited',\n",
       " 'uncover',\n",
       " 'salesdue',\n",
       " 'dear',\n",
       " 'tandem',\n",
       " 'abuse',\n",
       " 'declined',\n",
       " 'personthis',\n",
       " 'computation',\n",
       " 'noticefor',\n",
       " 'analytically',\n",
       " 'optoms',\n",
       " 'nick',\n",
       " 'rejects',\n",
       " 'nhsggcrecruitmentnhs',\n",
       " 'traineerecruitmentconsultant',\n",
       " 'borrowing',\n",
       " 'stamping',\n",
       " 'portugal',\n",
       " 'noncontact',\n",
       " 'version',\n",
       " 'subscriptions',\n",
       " 'psd',\n",
       " 'policymakers',\n",
       " 'carefinancial',\n",
       " 'pitch',\n",
       " \"friday's\",\n",
       " 'adolescent',\n",
       " 'sidcup',\n",
       " 'examples',\n",
       " 'recreational',\n",
       " 'rta',\n",
       " 'dmrb',\n",
       " 'transparently',\n",
       " 'qms',\n",
       " 'halls',\n",
       " 'graduatesalesexecutivetraineefieldsales',\n",
       " 'practicefull',\n",
       " 'disp',\n",
       " 'aelod',\n",
       " 'godalming',\n",
       " 'coatbridge',\n",
       " 'timezones',\n",
       " 'hazop',\n",
       " 'bartender',\n",
       " 'shrewsbury',\n",
       " 'cradle',\n",
       " 'ynni',\n",
       " 'downtime',\n",
       " 'brokerages',\n",
       " 'mccall',\n",
       " 'translational',\n",
       " 'hitech',\n",
       " 'acquisitive',\n",
       " 'glass',\n",
       " 'highreliability',\n",
       " 'dirty',\n",
       " 'pivot',\n",
       " 'seniordeveloperwithc',\n",
       " 'savouries',\n",
       " 'respects',\n",
       " 'accumulation',\n",
       " \"club's\",\n",
       " 'paediatrics',\n",
       " 'ovens',\n",
       " 'intially',\n",
       " 'longstanding',\n",
       " 'crossfunctional',\n",
       " 'risklead',\n",
       " 'honeywell',\n",
       " 'winchfield',\n",
       " 'yearfor',\n",
       " \"europe's\",\n",
       " 'mps',\n",
       " 'desirables',\n",
       " 'cafeteria',\n",
       " 'births',\n",
       " 'felt',\n",
       " 'themed',\n",
       " 'passenger',\n",
       " 'borner',\n",
       " 'fats',\n",
       " 'dialux',\n",
       " 'internationalsalesaccountmanagergermanmarket',\n",
       " 'tenaciousyou',\n",
       " 'receptionist',\n",
       " 'midmarketsalesexecutive',\n",
       " 'multiaward',\n",
       " 'rhannol',\n",
       " 'warwick',\n",
       " 'buxton',\n",
       " 'schemeoperationsadministrator',\n",
       " 'racheal',\n",
       " 'exploitations',\n",
       " 'detailoriented',\n",
       " 'overachieving',\n",
       " 'seniormechanicalcontractsmanager',\n",
       " 'saas',\n",
       " 'tackling',\n",
       " 'ebucklecompassltd',\n",
       " 'staffnurse',\n",
       " 'predicted',\n",
       " 'excellant',\n",
       " 'postal',\n",
       " 'faro',\n",
       " 'epitomise',\n",
       " 'formalising',\n",
       " 'incontinence',\n",
       " 'ondemand',\n",
       " 'defeat',\n",
       " 'eyecare',\n",
       " 'drywall',\n",
       " 'jim',\n",
       " 'prioritize',\n",
       " 'hamilton',\n",
       " 'farnham',\n",
       " 'epilepsy',\n",
       " 'ciob',\n",
       " 'dark',\n",
       " 'blueprint',\n",
       " 'flows',\n",
       " 'surpass',\n",
       " 'enthuse',\n",
       " 'battlewinning',\n",
       " 'spans',\n",
       " 'skillsmust',\n",
       " 'wearresistant',\n",
       " 'clyde',\n",
       " 'scour',\n",
       " 'motorsport',\n",
       " 'renovations',\n",
       " 'stratford',\n",
       " 'hurst',\n",
       " \"candidate's\",\n",
       " 'nterpersonal',\n",
       " 'utilization',\n",
       " 'totally',\n",
       " 'dorking',\n",
       " 'gladly',\n",
       " 'hannah',\n",
       " 'purchaseledgerclerk',\n",
       " 'buzzard',\n",
       " 'careersflamehealth',\n",
       " 'completions',\n",
       " 'mlss',\n",
       " 'farms',\n",
       " 'switch',\n",
       " 'matthewhayesfirstselection',\n",
       " 'groundbreaking',\n",
       " 'analyzing',\n",
       " 'pharmacists',\n",
       " 'pensionsandpayrollconsultant',\n",
       " 'directive',\n",
       " 'orrock',\n",
       " 'installs',\n",
       " 'outlet',\n",
       " 'uppersecond',\n",
       " 'rabaiotti',\n",
       " 'polishing',\n",
       " 'ncr',\n",
       " 'renal',\n",
       " 'glendundee',\n",
       " 'calmly',\n",
       " 'wing',\n",
       " 'learnt',\n",
       " 'indicating',\n",
       " \"solution's\",\n",
       " 'earthmoving',\n",
       " 'negligible',\n",
       " 'enters',\n",
       " 'uphold',\n",
       " 'mobilise',\n",
       " 'withbusiness',\n",
       " 'pupils',\n",
       " 'amx',\n",
       " 'currencies',\n",
       " 'introducers',\n",
       " 'htm',\n",
       " 'emp',\n",
       " 'servicebased',\n",
       " 'phy',\n",
       " 'wilmslow',\n",
       " 'jobstriumph',\n",
       " 'shore',\n",
       " 'breaks',\n",
       " 'selfregulated',\n",
       " 'replenish',\n",
       " 'toil',\n",
       " 'reproduction',\n",
       " 'apologies',\n",
       " 'kvgncpopulusconsultants',\n",
       " 'experiencedmachinistverticalborerheavyengineering',\n",
       " 'infirmary',\n",
       " 'finishers',\n",
       " 'rotary',\n",
       " 'cleint',\n",
       " 'yvonne',\n",
       " 'npi',\n",
       " 'arada',\n",
       " 'pvc',\n",
       " 'bridgend',\n",
       " 'opdef',\n",
       " 'telecommunication',\n",
       " 'bmssales',\n",
       " 'lengthy',\n",
       " 'hindsight',\n",
       " 'banding',\n",
       " 'farnborough',\n",
       " 'confused',\n",
       " 'truro',\n",
       " 'watching',\n",
       " 'classen',\n",
       " 'seniorbrokerslondon',\n",
       " 'electrifying',\n",
       " 'affiliate',\n",
       " 'bitton',\n",
       " 'settlements',\n",
       " 'storemanagerfurniturecarpets',\n",
       " 'internalauditmanager',\n",
       " 'modularizing',\n",
       " 'flexitime',\n",
       " 'gatwick',\n",
       " 'holidayabout',\n",
       " 'phones',\n",
       " 'cambs',\n",
       " 'automating',\n",
       " 'precedents',\n",
       " 'adlington',\n",
       " 'stokeontrent',\n",
       " 'highlyskilled',\n",
       " 'bsuiness',\n",
       " 'constcarillion',\n",
       " 'fide',\n",
       " 'datblygiad',\n",
       " 'internships',\n",
       " 'gradually',\n",
       " 'grievance',\n",
       " 'laois',\n",
       " 'seal',\n",
       " 'safeguard',\n",
       " 'cifs',\n",
       " 'ddylunio',\n",
       " 'toworking',\n",
       " 'stan',\n",
       " 'gvs',\n",
       " 'rpo',\n",
       " 'scripts',\n",
       " 'ddefnyddio',\n",
       " 'sainsbury',\n",
       " 'nonmedical',\n",
       " 'entertaining',\n",
       " 'frics',\n",
       " 'midlife',\n",
       " 'grand',\n",
       " 'substantiation',\n",
       " 'energised',\n",
       " 'thenecessary',\n",
       " 'organiser',\n",
       " 'expereince',\n",
       " 'mcc',\n",
       " 'thickness',\n",
       " 'ing',\n",
       " 'secondtonone',\n",
       " 'extrusions',\n",
       " 'escalates',\n",
       " 'kerr',\n",
       " 'activitiesfor',\n",
       " 'edmonton',\n",
       " 'kingswodd',\n",
       " 'dads',\n",
       " 'nonlife',\n",
       " 'irregularities',\n",
       " 'subsided',\n",
       " 'proficiency',\n",
       " 'safehands',\n",
       " 'chriscavendishmaine',\n",
       " 'leavers',\n",
       " 'temps',\n",
       " 'consequence',\n",
       " 'teamto',\n",
       " 'youselling',\n",
       " 'frequent',\n",
       " 'grind',\n",
       " 'devoted',\n",
       " 'senioreducationrecruitmentconsultantbirmingham',\n",
       " 'complications',\n",
       " 'plain',\n",
       " 'couples',\n",
       " 'plowe',\n",
       " 'execute',\n",
       " 'meters',\n",
       " 'staggering',\n",
       " 'packaged',\n",
       " 'sortec',\n",
       " 'availablefollow',\n",
       " 'appeared',\n",
       " 'freshly',\n",
       " 'cgmp',\n",
       " 'stretch',\n",
       " 'salesmanagermedicalsalesexecutive',\n",
       " 'contaminant',\n",
       " 'lamps',\n",
       " 'dairy',\n",
       " 'taysidenhs',\n",
       " 'projectspecific',\n",
       " 'offaly',\n",
       " 'assembling',\n",
       " 'talents',\n",
       " 'catchment',\n",
       " 'petrophysics',\n",
       " 'cafes',\n",
       " 'gatekeeper',\n",
       " 'haves',\n",
       " 'robinsonappointgroup',\n",
       " 'reaching',\n",
       " 'upkeep',\n",
       " 'dyfodol',\n",
       " 'bestival',\n",
       " 'learned',\n",
       " 'builder',\n",
       " 'adoperation',\n",
       " 'laundryfieldserviceengineergloucester',\n",
       " 'leverage',\n",
       " 'steelwork',\n",
       " 'rhaid',\n",
       " 'outofhours',\n",
       " 'umms',\n",
       " 'gael',\n",
       " 'blind',\n",
       " 'stationary',\n",
       " 'wells',\n",
       " 'launches',\n",
       " 'probity',\n",
       " 'oknowledge',\n",
       " 'bran',\n",
       " 'awconsultingltd',\n",
       " \"crb's\",\n",
       " 'alban',\n",
       " 'ashworth',\n",
       " 'smb',\n",
       " 'wrigley',\n",
       " 'morekare',\n",
       " 'citations',\n",
       " 'accreditations',\n",
       " 'deepwater',\n",
       " 'embolization',\n",
       " 'prm',\n",
       " 'gds',\n",
       " 'collaborative',\n",
       " 'sclerosis',\n",
       " 'ssembling',\n",
       " 'culminating',\n",
       " 'servicesaround',\n",
       " 'sean',\n",
       " 'weeklocation',\n",
       " 'hillyard',\n",
       " 'pair',\n",
       " 'visualstudioskills',\n",
       " 'saleswork',\n",
       " 'dietry',\n",
       " 'deypenguinrecruitment',\n",
       " 'staffed',\n",
       " 'melbourne',\n",
       " 'representations',\n",
       " 'regs',\n",
       " 'grass',\n",
       " 'concession',\n",
       " 'consultatively',\n",
       " 'cti',\n",
       " 'cysylltwch',\n",
       " 'tcg',\n",
       " 'healthcarewith',\n",
       " 'mark',\n",
       " 'mus',\n",
       " 'retailenergyexpert',\n",
       " 'lynch',\n",
       " 'tpn',\n",
       " 'sterile',\n",
       " 'fmmedia',\n",
       " 'arrived',\n",
       " 'nsrp',\n",
       " 'objectoriented',\n",
       " 'overnights',\n",
       " 'aspires',\n",
       " 'biotechnology',\n",
       " 'angle',\n",
       " 'peirianneg',\n",
       " 'genres',\n",
       " 'eta',\n",
       " 'yearly',\n",
       " 'tsi',\n",
       " 'leg',\n",
       " 'analytic',\n",
       " 'trucks',\n",
       " 'independantly',\n",
       " 'coat',\n",
       " 'crowd',\n",
       " 'riskandcompliancemanagercardpaymentswatford',\n",
       " 'setters',\n",
       " 'directs',\n",
       " 'travels',\n",
       " 'bots',\n",
       " \"driver's\",\n",
       " 'selfservice',\n",
       " 'cliche',\n",
       " 'achieves',\n",
       " 'realisation',\n",
       " 'cavelle',\n",
       " 'welded',\n",
       " 'joannaaesco',\n",
       " 'lawesrecruitment',\n",
       " 'appealing',\n",
       " 'mathlab',\n",
       " 'preeminence',\n",
       " 'gormod',\n",
       " 'refresher',\n",
       " 'renown',\n",
       " 'str',\n",
       " 'mau',\n",
       " 'borland',\n",
       " 'maximo',\n",
       " 'cpb',\n",
       " 'hackney',\n",
       " 'marks',\n",
       " 'bradshaw',\n",
       " 'marsdenomnirms',\n",
       " 'sut',\n",
       " 'usage',\n",
       " 'deserved',\n",
       " 'converged',\n",
       " 'esk',\n",
       " 'fordingbridge',\n",
       " 'indications',\n",
       " 'weaknesses',\n",
       " 'diarising',\n",
       " 'leoedd',\n",
       " 'managerkareplus',\n",
       " 'kitchens',\n",
       " 'swanage',\n",
       " 'moss',\n",
       " 'datacentre',\n",
       " 'serviceuser',\n",
       " 'literateexperience',\n",
       " 'neurone',\n",
       " 'solutionsales',\n",
       " 'airconditioningengineer',\n",
       " 'buttress',\n",
       " 'vice',\n",
       " 'accompanied',\n",
       " 'scr',\n",
       " 'crosssite',\n",
       " 'crawfordablyresources',\n",
       " 'intrastat',\n",
       " 'ulcers',\n",
       " 'transition',\n",
       " 'gryfhau',\n",
       " 'resonsibilities',\n",
       " 'organisers',\n",
       " 'apprentices',\n",
       " 'barclay',\n",
       " 'fidic',\n",
       " 'assistive',\n",
       " 'negotiates',\n",
       " 'holsbenefits',\n",
       " 'lunchtime',\n",
       " 'dogfennau',\n",
       " 'tenanted',\n",
       " 'judith',\n",
       " 'austell',\n",
       " 'realstaffing',\n",
       " 'bridport',\n",
       " 'specs',\n",
       " 'blaenoriaethu',\n",
       " 'laid',\n",
       " 'fieldsaleselectricalwholesalebirminghamsouthlondon',\n",
       " 'standardisation',\n",
       " 'withstand',\n",
       " 'draughting',\n",
       " \"coding's\",\n",
       " 'academies',\n",
       " 'completes',\n",
       " 'stripping',\n",
       " 'castleford',\n",
       " 'byfleet',\n",
       " 'fbk',\n",
       " 'forget',\n",
       " 'multiindustry',\n",
       " 'baileynorthstaffs',\n",
       " 'absorb',\n",
       " 'costeffective',\n",
       " 'tutbury',\n",
       " 'megh',\n",
       " 'brosiectau',\n",
       " 'radius',\n",
       " 'modernisation',\n",
       " 'expressed',\n",
       " 'surreysalary',\n",
       " 'meade',\n",
       " 'knowing',\n",
       " 'scientist',\n",
       " 'cooperlogicalps',\n",
       " 'viable',\n",
       " 'chubb',\n",
       " 'microprocessors',\n",
       " 'workinprogress',\n",
       " \"gyda'r\",\n",
       " 'substantially',\n",
       " 'appendage',\n",
       " 'spam',\n",
       " 'onpatch',\n",
       " 'unlawful',\n",
       " 'crafts',\n",
       " 'taxfree',\n",
       " 'wrexham',\n",
       " 'ajc',\n",
       " 'practises',\n",
       " 'atleast',\n",
       " 'salespurchaseledgerclerkmaternitycover',\n",
       " 'hdu',\n",
       " 'permitted',\n",
       " 'misselling',\n",
       " 'pfis',\n",
       " 'overflow',\n",
       " 'alot',\n",
       " 'objectorientated',\n",
       " 'prefect',\n",
       " 'testers',\n",
       " 'bristolbased',\n",
       " 'appeals',\n",
       " 'helens',\n",
       " 'linear',\n",
       " 'therapeutics',\n",
       " 'finishing',\n",
       " 'wares',\n",
       " 'mcafee',\n",
       " 'fieldsalesexecutivesoftwareprinthardwaredocumentsolutions',\n",
       " 'huntress',\n",
       " 'realization',\n",
       " 'ofsted',\n",
       " 'lawrence',\n",
       " 'kpderbykareplus',\n",
       " 'kennedyrandstad',\n",
       " 'labview',\n",
       " 'allocate',\n",
       " 'fellows',\n",
       " 'widen',\n",
       " 'recuse',\n",
       " 'vaccinations',\n",
       " 'welleducated',\n",
       " 'brwdfrydedd',\n",
       " 'weybridge',\n",
       " 'philip',\n",
       " 'fin',\n",
       " 'kinross',\n",
       " 'chelsea',\n",
       " 'origins',\n",
       " 'valueadded',\n",
       " 'menu',\n",
       " 'callington',\n",
       " 'universitystrong',\n",
       " 'experiments',\n",
       " 'infrastructures',\n",
       " 'bydd',\n",
       " 'broadcasters',\n",
       " 'parttimepayrollclerk',\n",
       " 'lies',\n",
       " 'burnhamonsea',\n",
       " 'discharges',\n",
       " 'iee',\n",
       " \"builder's\",\n",
       " 'ent',\n",
       " 'improper',\n",
       " 'pensiojn',\n",
       " 'articulately',\n",
       " 'extraordinary',\n",
       " 'swindon',\n",
       " 'yourprimary',\n",
       " 'kgv',\n",
       " 'loader',\n",
       " 'eyre',\n",
       " 'jobopps',\n",
       " 'wembley',\n",
       " 'linesconducting',\n",
       " 'commissioned',\n",
       " 'authoring',\n",
       " 'aftercareskills',\n",
       " 'finalising',\n",
       " 'folder',\n",
       " 'equitrac',\n",
       " 'testexec',\n",
       " 'linq',\n",
       " 'icas',\n",
       " 'designfocused',\n",
       " 'seniormanufacturingengineer',\n",
       " 'kpmg',\n",
       " 'subassemblies',\n",
       " 'electric',\n",
       " 'captured',\n",
       " 'consutative',\n",
       " 'addon',\n",
       " 'riskunderstanding',\n",
       " 'testability',\n",
       " 'garner',\n",
       " 'reductions',\n",
       " 'august',\n",
       " 'derbyn',\n",
       " 'faint',\n",
       " 'exposed',\n",
       " 'isl',\n",
       " 'percentage',\n",
       " 'alzheimer',\n",
       " 'checklists',\n",
       " 'oversees',\n",
       " 'renewables',\n",
       " 'hatstand',\n",
       " 'physiotherapists',\n",
       " 'ryan',\n",
       " 'veterinary',\n",
       " 'regulatorsexcellent',\n",
       " 'priv',\n",
       " 'misdescriptions',\n",
       " 'homebased',\n",
       " 'bridgwater',\n",
       " 'soidworks',\n",
       " 'redecoration',\n",
       " 'diversified',\n",
       " 'risksbuild',\n",
       " 'southeast',\n",
       " 'remake',\n",
       " 'stsm',\n",
       " 'tgargettredlinegroup',\n",
       " 'peiriannu',\n",
       " 'marketsstrong',\n",
       " 'timothy',\n",
       " 'constituent',\n",
       " 'tonometers',\n",
       " 'restructures',\n",
       " 'envelope',\n",
       " 'taxis',\n",
       " 'bojang',\n",
       " 'compentent',\n",
       " 'witnesses',\n",
       " 'fat',\n",
       " 'diffuse',\n",
       " \"people's\",\n",
       " 'experiencedegree',\n",
       " 'connells',\n",
       " 'stepping',\n",
       " 'informatio',\n",
       " 'lpc',\n",
       " 'necessity',\n",
       " 'delegated',\n",
       " 'advertisers',\n",
       " 'nice',\n",
       " 'purposely',\n",
       " 'cvi',\n",
       " 'weare',\n",
       " 'spinalcord',\n",
       " 'dep',\n",
       " 'fanyleb',\n",
       " 'fieldsalesexecutive',\n",
       " 'pest',\n",
       " 'distract',\n",
       " 'bromsgrove',\n",
       " 'purely',\n",
       " 'belong',\n",
       " 'felicityapprenticesales',\n",
       " 'apprenticed',\n",
       " 'gloucs',\n",
       " 'conforms',\n",
       " 'winder',\n",
       " 'werkshage',\n",
       " 'projectbased',\n",
       " 'lawful',\n",
       " 'trollies',\n",
       " 'exmouth',\n",
       " 'earthstream',\n",
       " 'ado',\n",
       " 'mechanic',\n",
       " 'qpa',\n",
       " 'jtag',\n",
       " 'administrating',\n",
       " \"giftware's\",\n",
       " 'coachable',\n",
       " 'knocking',\n",
       " 'impacting',\n",
       " 'gmo',\n",
       " 'liam',\n",
       " ...}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Less frequent words based on term frequency\n",
    "\n",
    "rare_words = set(term_freq.hapaxes())\n",
    "rare_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove words\n",
    "\n",
    "def removeWords(descp,exclude):\n",
    "    \"\"\"\n",
    "    Function to remove words form description, works for both rare and most common words\n",
    "    \"\"\"\n",
    "    return [w for w in descp if w not in exclude]\n",
    "\n",
    "tk_descriptions = [removeWords(descp,rare_words) for descp in tk_descriptions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size:  5108\n",
      "Total number of tokens:  100062\n",
      "Lexical diversity:  0.05104835002298575\n",
      "Total number of description: 776\n",
      "Average description length: 128.9458762886598\n",
      "Maximun description length: 466\n",
      "Minimun description length: 1\n",
      "Standard deviation of description length: 71.24901633254898\n"
     ]
    }
   ],
   "source": [
    "stats_print(tk_descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('experience', 579),\n",
       " ('role', 495),\n",
       " ('work', 445),\n",
       " ('team', 427),\n",
       " ('working', 402)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# most frequent words\n",
    "\n",
    "common_words = list(chain.from_iterable([set(descp) for descp in tk_descriptions]))\n",
    "\n",
    "doc_freq = FreqDist(common_words)\n",
    "doc_freq.most_common(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['experience',\n",
       " 'role',\n",
       " 'work',\n",
       " 'team',\n",
       " 'working',\n",
       " 'skills',\n",
       " 'client',\n",
       " 'job',\n",
       " 'business',\n",
       " 'company',\n",
       " 'excellent',\n",
       " 'management',\n",
       " 'based',\n",
       " 'apply',\n",
       " 'opportunity',\n",
       " 'salary',\n",
       " 'required',\n",
       " 'successful',\n",
       " 'support',\n",
       " 'join',\n",
       " 'candidate',\n",
       " 'knowledge',\n",
       " 'service',\n",
       " 'development',\n",
       " 'leading',\n",
       " 'high',\n",
       " 'manager',\n",
       " 'www',\n",
       " 'training',\n",
       " 'strong',\n",
       " 'sales',\n",
       " 'including',\n",
       " 'provide',\n",
       " 'services',\n",
       " 'ability',\n",
       " 'contact',\n",
       " 'position',\n",
       " 'full',\n",
       " 'posted',\n",
       " 'recruitment',\n",
       " 'jobseeking',\n",
       " 'originally',\n",
       " 'benefits',\n",
       " 'include',\n",
       " 'essential',\n",
       " 'good',\n",
       " 'clients',\n",
       " 'communication',\n",
       " 'information',\n",
       " 'customer']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top50_common_words = [word for word, freq in doc_freq.most_common(50)]\n",
    "top50_common_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_before = list(chain.from_iterable(tk_descriptions))\n",
    "vocab_before = set(words_before) \n",
    "tk_descriptions_before = tk_descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "tk_descriptions = [removeWords(descp,top50_common_words) for descp in tk_descriptions] # remove top 50 most common words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "removed = []\n",
    "for x in tk_descriptions_before:\n",
    "    if x not in tk_descriptions:\n",
    "        removed.append(x)\n",
    "removed = list(chain.from_iterable(removed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_after = list(chain.from_iterable(tk_descriptions))\n",
    "vocab_after = set(words_after) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 50 number of common words.\n"
     ]
    }
   ],
   "source": [
    "removed = list(vocab_before - vocab_after)  # words before - words after\n",
    "print(f\"Removed {len(removed)} number of common words.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(set(), set())"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff1 = set(top50_common_words) - set(removed)\n",
    "diff2 = set(removed) - set(top50_common_words)\n",
    "diff1, diff2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like all top 50 words are removed :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size:  5058\n",
      "Total number of tokens:  78819\n",
      "Lexical diversity:  0.06417234423172077\n",
      "Total number of description: 776\n",
      "Average description length: 101.57087628865979\n",
      "Maximun description length: 392\n",
      "Minimun description length: 0\n",
      "Standard deviation of description length: 58.893164037654984\n"
     ]
    }
   ],
   "source": [
    "stats_print(tk_descriptions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____________________________________________\n",
    "\n",
    "Vocabulary size:  9779  \n",
    "Total number of tokens:  184038  \n",
    "Lexical diversity:  0.05313576543974614  \n",
    "Total number of description: 776  \n",
    "Average description length: 237.16237113402062  \n",
    "Maximun description length: 815  \n",
    "Minimun description length: 1  \n",
    "Standard deviation of description length: 128.22977695321202\n",
    "_____________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The vocabulary size has decreased by approximately 48.3%, and the number of tokens has been reduced by over half. Additionally, there is an improvement of approximately 20% in the lexical diversity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the pre processing is done, now saving the final words and vocab data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final words and vocab\n",
    "words = list(chain.from_iterable(tk_descriptions))\n",
    "vocab = set(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_vocab = sorted(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'aap': 0,\n",
       " 'aaron': 1,\n",
       " 'aat': 2,\n",
       " 'abb': 3,\n",
       " 'abenefit': 4,\n",
       " 'aberdeen': 5,\n",
       " 'abi': 6,\n",
       " 'abilities': 7,\n",
       " 'abreast': 8,\n",
       " 'abroad': 9,\n",
       " 'absence': 10,\n",
       " 'absolute': 11,\n",
       " 'aca': 12,\n",
       " 'academic': 13,\n",
       " 'academy': 14,\n",
       " 'acca': 15,\n",
       " 'accept': 16,\n",
       " 'acceptable': 17,\n",
       " 'acceptance': 18,\n",
       " 'accepted': 19,\n",
       " 'access': 20,\n",
       " 'accessible': 21,\n",
       " 'accident': 22,\n",
       " 'accommodates': 23,\n",
       " 'accommodation': 24,\n",
       " 'accomplished': 25,\n",
       " 'accordance': 26,\n",
       " 'account': 27,\n",
       " 'accountabilities': 28,\n",
       " 'accountability': 29,\n",
       " 'accountable': 30,\n",
       " 'accountancy': 31,\n",
       " 'accountant': 32,\n",
       " 'accountants': 33,\n",
       " 'accounting': 34,\n",
       " 'accounts': 35,\n",
       " 'accreditation': 36,\n",
       " 'accredited': 37,\n",
       " 'accruals': 38,\n",
       " 'accuracy': 39,\n",
       " 'accurate': 40,\n",
       " 'accurately': 41,\n",
       " 'achievable': 42,\n",
       " 'achieve': 43,\n",
       " 'achieved': 44,\n",
       " 'achievement': 45,\n",
       " 'achievements': 46,\n",
       " 'achiever': 47,\n",
       " 'achieving': 48,\n",
       " 'acii': 49,\n",
       " 'acquired': 50,\n",
       " 'acquisition': 51,\n",
       " 'acquisitions': 52,\n",
       " 'act': 53,\n",
       " 'acting': 54,\n",
       " 'action': 55,\n",
       " 'actions': 56,\n",
       " 'actionscript': 57,\n",
       " 'active': 58,\n",
       " 'actively': 59,\n",
       " 'activites': 60,\n",
       " 'activities': 61,\n",
       " 'activity': 62,\n",
       " 'acts': 63,\n",
       " 'actual': 64,\n",
       " 'actuarial': 65,\n",
       " 'acumen': 66,\n",
       " 'acute': 67,\n",
       " 'adam': 68,\n",
       " 'adapt': 69,\n",
       " 'adaptability': 70,\n",
       " 'add': 71,\n",
       " 'added': 72,\n",
       " 'addiction': 73,\n",
       " 'adding': 74,\n",
       " 'addition': 75,\n",
       " 'additional': 76,\n",
       " 'additionally': 77,\n",
       " 'additions': 78,\n",
       " 'address': 79,\n",
       " 'addresses': 80,\n",
       " 'addressing': 81,\n",
       " 'adecco': 82,\n",
       " 'adept': 83,\n",
       " 'adequacy': 84,\n",
       " 'adequate': 85,\n",
       " 'adequately': 86,\n",
       " 'adhere': 87,\n",
       " 'adhered': 88,\n",
       " 'adherence': 89,\n",
       " 'adhering': 90,\n",
       " 'adhoc': 91,\n",
       " 'adjust': 92,\n",
       " 'adjuster': 93,\n",
       " 'adjusting': 94,\n",
       " 'adjustments': 95,\n",
       " 'admin': 96,\n",
       " 'administer': 97,\n",
       " 'administered': 98,\n",
       " 'administering': 99,\n",
       " 'administration': 100,\n",
       " 'administrative': 101,\n",
       " 'administrator': 102,\n",
       " 'administrators': 103,\n",
       " 'admission': 104,\n",
       " 'admissions': 105,\n",
       " 'adobe': 106,\n",
       " 'adolescents': 107,\n",
       " 'adopt': 108,\n",
       " 'adopted': 109,\n",
       " 'adopting': 110,\n",
       " 'adrian': 111,\n",
       " 'ads': 112,\n",
       " 'adstream': 113,\n",
       " 'adult': 114,\n",
       " 'adults': 115,\n",
       " 'advance': 116,\n",
       " 'advanced': 117,\n",
       " 'advancement': 118,\n",
       " 'advances': 119,\n",
       " 'advantage': 120,\n",
       " 'advantageous': 121,\n",
       " 'advert': 122,\n",
       " 'advertise': 123,\n",
       " 'advertised': 124,\n",
       " 'advertisement': 125,\n",
       " 'advertising': 126,\n",
       " 'advertsing': 127,\n",
       " 'advice': 128,\n",
       " 'advise': 129,\n",
       " 'advised': 130,\n",
       " 'adviser': 131,\n",
       " 'advisers': 132,\n",
       " 'advising': 133,\n",
       " 'advisor': 134,\n",
       " 'advisors': 135,\n",
       " 'advisory': 136,\n",
       " 'aeronautical': 137,\n",
       " 'aerospace': 138,\n",
       " 'affairs': 139,\n",
       " 'affect': 140,\n",
       " 'affected': 141,\n",
       " 'affecting': 142,\n",
       " 'affinity': 143,\n",
       " 'affordable': 144,\n",
       " 'africa': 145,\n",
       " 'aftermarket': 146,\n",
       " 'afternoon': 147,\n",
       " 'afternoons': 148,\n",
       " 'age': 149,\n",
       " 'aged': 150,\n",
       " 'agencies': 151,\n",
       " 'agency': 152,\n",
       " 'agent': 153,\n",
       " 'agents': 154,\n",
       " 'ages': 155,\n",
       " 'aggressive': 156,\n",
       " 'agile': 157,\n",
       " 'ago': 158,\n",
       " 'agree': 159,\n",
       " 'agreed': 160,\n",
       " 'agreement': 161,\n",
       " 'agreements': 162,\n",
       " 'agy': 163,\n",
       " 'ahead': 164,\n",
       " 'ahu': 165,\n",
       " 'aid': 166,\n",
       " 'aided': 167,\n",
       " 'aids': 168,\n",
       " 'aim': 169,\n",
       " 'aimed': 170,\n",
       " 'aims': 171,\n",
       " 'air': 172,\n",
       " 'aircraft': 173,\n",
       " 'airdrie': 174,\n",
       " 'alarm': 175,\n",
       " 'alarms': 176,\n",
       " 'albans': 177,\n",
       " 'alcohol': 178,\n",
       " 'aldredirweb': 179,\n",
       " 'alecto': 180,\n",
       " 'alerting': 181,\n",
       " 'alex': 182,\n",
       " 'algorithm': 183,\n",
       " 'algorithms': 184,\n",
       " 'aligned': 185,\n",
       " 'alignment': 186,\n",
       " 'alike': 187,\n",
       " 'allied': 188,\n",
       " 'allocated': 189,\n",
       " 'allocation': 190,\n",
       " 'allowance': 191,\n",
       " 'allowances': 192,\n",
       " 'allowing': 193,\n",
       " 'alm': 194,\n",
       " 'alongside': 195,\n",
       " 'alternate': 196,\n",
       " 'alternative': 197,\n",
       " 'alternatively': 198,\n",
       " 'altrincham': 199,\n",
       " 'aluminium': 200,\n",
       " 'amazing': 201,\n",
       " 'ambassador': 202,\n",
       " 'ambition': 203,\n",
       " 'ambitious': 204,\n",
       " 'ambridge': 205,\n",
       " 'amenities': 206,\n",
       " 'america': 207,\n",
       " 'american': 208,\n",
       " 'amigo': 209,\n",
       " 'aml': 210,\n",
       " 'amount': 211,\n",
       " 'amounts': 212,\n",
       " 'amp': 213,\n",
       " 'amrywiol': 214,\n",
       " 'anaesthetics': 215,\n",
       " 'anaesthetist': 216,\n",
       " 'analog': 217,\n",
       " 'analogue': 218,\n",
       " 'analyse': 219,\n",
       " 'analysers': 220,\n",
       " 'analyses': 221,\n",
       " 'analysing': 222,\n",
       " 'analysis': 223,\n",
       " 'analyst': 224,\n",
       " 'analystbelfast': 225,\n",
       " 'analysts': 226,\n",
       " 'analytical': 227,\n",
       " 'analytics': 228,\n",
       " 'ancillary': 229,\n",
       " 'andoffers': 230,\n",
       " 'andrew': 231,\n",
       " 'android': 232,\n",
       " 'androidoptometryapp': 233,\n",
       " 'andy': 234,\n",
       " 'angiography': 235,\n",
       " 'anglia': 236,\n",
       " 'annual': 237,\n",
       " 'annum': 238,\n",
       " 'anomalies': 239,\n",
       " 'answer': 240,\n",
       " 'answered': 241,\n",
       " 'answering': 242,\n",
       " 'anthony': 243,\n",
       " 'anticipate': 244,\n",
       " 'anticipated': 245,\n",
       " 'antony': 246,\n",
       " 'apartments': 247,\n",
       " 'api': 248,\n",
       " 'apmp': 249,\n",
       " 'appearance': 250,\n",
       " 'appetite': 251,\n",
       " 'appleoptometry': 252,\n",
       " 'applicable': 253,\n",
       " 'applicant': 254,\n",
       " 'applicants': 255,\n",
       " 'application': 256,\n",
       " 'applications': 257,\n",
       " 'applied': 258,\n",
       " 'applies': 259,\n",
       " 'applying': 260,\n",
       " 'appoint': 261,\n",
       " 'appointed': 262,\n",
       " 'appointment': 263,\n",
       " 'appointments': 264,\n",
       " 'appraisal': 265,\n",
       " 'appraisals': 266,\n",
       " 'appraising': 267,\n",
       " 'appreciation': 268,\n",
       " 'apprentice': 269,\n",
       " 'apprenticeship': 270,\n",
       " 'approach': 271,\n",
       " 'approachable': 272,\n",
       " 'approaches': 273,\n",
       " 'appropriately': 274,\n",
       " 'approval': 275,\n",
       " 'approved': 276,\n",
       " 'approx': 277,\n",
       " 'approximately': 278,\n",
       " 'aptitude': 279,\n",
       " 'aptrack': 280,\n",
       " 'architect': 281,\n",
       " 'architects': 282,\n",
       " 'architectural': 283,\n",
       " 'architecture': 284,\n",
       " 'architectures': 285,\n",
       " 'archiving': 286,\n",
       " 'area': 287,\n",
       " 'areas': 288,\n",
       " 'arena': 289,\n",
       " 'arise': 290,\n",
       " 'arisen': 291,\n",
       " 'arm': 292,\n",
       " 'arrange': 293,\n",
       " 'arranged': 294,\n",
       " 'arrangement': 295,\n",
       " 'arrangements': 296,\n",
       " 'arranging': 297,\n",
       " 'array': 298,\n",
       " 'arrow': 299,\n",
       " 'art': 300,\n",
       " 'articulate': 301,\n",
       " 'articulating': 302,\n",
       " 'artists': 303,\n",
       " 'asap': 304,\n",
       " 'asbestos': 305,\n",
       " 'ascertain': 306,\n",
       " 'ascot': 307,\n",
       " 'asda': 308,\n",
       " 'ashby': 309,\n",
       " 'ashford': 310,\n",
       " 'ashley': 311,\n",
       " 'asia': 312,\n",
       " 'asic': 313,\n",
       " 'asked': 314,\n",
       " 'asp': 315,\n",
       " 'aspect': 316,\n",
       " 'aspects': 317,\n",
       " 'aspirations': 318,\n",
       " 'aspire': 319,\n",
       " 'aspireinc': 320,\n",
       " 'assembler': 321,\n",
       " 'assemblies': 322,\n",
       " 'assembly': 323,\n",
       " 'assertive': 324,\n",
       " 'assess': 325,\n",
       " 'assessed': 326,\n",
       " 'assessing': 327,\n",
       " 'assessment': 328,\n",
       " 'assessments': 329,\n",
       " 'assessor': 330,\n",
       " 'assessors': 331,\n",
       " 'asset': 332,\n",
       " 'assets': 333,\n",
       " 'assigned': 334,\n",
       " 'assignment': 335,\n",
       " 'assignments': 336,\n",
       " 'assimilate': 337,\n",
       " 'assist': 338,\n",
       " 'assistance': 339,\n",
       " 'assistant': 340,\n",
       " 'assistants': 341,\n",
       " 'assisted': 342,\n",
       " 'assisting': 343,\n",
       " 'assists': 344,\n",
       " 'associate': 345,\n",
       " 'associates': 346,\n",
       " 'association': 347,\n",
       " 'assume': 348,\n",
       " 'assuming': 349,\n",
       " 'assumptions': 350,\n",
       " 'assurance': 351,\n",
       " 'assured': 352,\n",
       " 'astute': 353,\n",
       " 'ate': 354,\n",
       " 'atmosphere': 355,\n",
       " 'att': 356,\n",
       " 'attached': 357,\n",
       " 'attend': 358,\n",
       " 'attendance': 359,\n",
       " 'attending': 360,\n",
       " 'attention': 361,\n",
       " 'attitude': 362,\n",
       " 'attitudes': 363,\n",
       " 'attract': 364,\n",
       " 'attracting': 365,\n",
       " 'attractive': 366,\n",
       " 'attracts': 367,\n",
       " 'attributes': 368,\n",
       " 'audi': 369,\n",
       " 'audience': 370,\n",
       " 'audiences': 371,\n",
       " 'audio': 372,\n",
       " 'audit': 373,\n",
       " 'auditing': 374,\n",
       " 'auditor': 375,\n",
       " 'auditors': 376,\n",
       " 'audits': 377,\n",
       " 'authorisation': 378,\n",
       " 'authorised': 379,\n",
       " 'authorities': 380,\n",
       " 'authority': 381,\n",
       " 'authorized': 382,\n",
       " 'autism': 383,\n",
       " 'auto': 384,\n",
       " 'autocad': 385,\n",
       " 'autodesk': 386,\n",
       " 'automated': 387,\n",
       " 'automatic': 388,\n",
       " 'automatically': 389,\n",
       " 'automation': 390,\n",
       " 'automotive': 391,\n",
       " 'autonomous': 392,\n",
       " 'autonomously': 393,\n",
       " 'autonomy': 394,\n",
       " 'auxiliaries': 395,\n",
       " 'auxiliary': 396,\n",
       " 'availability': 397,\n",
       " 'avenues': 398,\n",
       " 'average': 399,\n",
       " 'avon': 400,\n",
       " 'avse': 401,\n",
       " 'award': 402,\n",
       " 'awarded': 403,\n",
       " 'awards': 404,\n",
       " 'awardwinning': 405,\n",
       " 'aware': 406,\n",
       " 'awareness': 407,\n",
       " 'axapta': 408,\n",
       " 'axis': 409,\n",
       " 'aylesbury': 410,\n",
       " 'bachelor': 411,\n",
       " \"bachelor's\": 412,\n",
       " 'back': 413,\n",
       " 'backed': 414,\n",
       " 'backend': 415,\n",
       " 'background': 416,\n",
       " 'backgrounds': 417,\n",
       " 'backing': 418,\n",
       " 'backtesting': 419,\n",
       " 'backup': 420,\n",
       " 'bacs': 421,\n",
       " 'badenoch': 422,\n",
       " 'bailey': 423,\n",
       " 'baking': 424,\n",
       " 'balance': 425,\n",
       " 'balances': 426,\n",
       " 'band': 427,\n",
       " 'bank': 428,\n",
       " 'banking': 429,\n",
       " 'banks': 430,\n",
       " 'barchester': 431,\n",
       " \"barchester's\": 432,\n",
       " 'barns': 433,\n",
       " 'barnsley': 434,\n",
       " 'barry': 435,\n",
       " 'base': 436,\n",
       " 'baseband': 437,\n",
       " 'basel': 438,\n",
       " 'bases': 439,\n",
       " 'basic': 440,\n",
       " 'basingstoke': 441,\n",
       " 'basis': 442,\n",
       " 'batch': 443,\n",
       " 'bath': 444,\n",
       " 'bathing': 445,\n",
       " 'bathroom': 446,\n",
       " 'bathrooms': 447,\n",
       " 'bdm': 448,\n",
       " 'beacon': 449,\n",
       " 'bearings': 450,\n",
       " 'beautiful': 451,\n",
       " 'becky': 452,\n",
       " 'bed': 453,\n",
       " 'bedded': 454,\n",
       " 'bedford': 455,\n",
       " 'bedfordshire': 456,\n",
       " 'beds': 457,\n",
       " 'began': 458,\n",
       " 'begin': 459,\n",
       " 'behalf': 460,\n",
       " 'behaviour': 461,\n",
       " 'behavioural': 462,\n",
       " 'behaviours': 463,\n",
       " 'belfast': 464,\n",
       " 'belief': 465,\n",
       " 'believes': 466,\n",
       " 'bell': 467,\n",
       " 'belt': 468,\n",
       " 'ben': 469,\n",
       " 'bench': 470,\n",
       " 'beneficial': 471,\n",
       " 'beneficiaries': 472,\n",
       " 'benefit': 473,\n",
       " 'benelux': 474,\n",
       " 'beng': 475,\n",
       " 'benn': 476,\n",
       " 'bens': 477,\n",
       " 'berkshire': 478,\n",
       " 'bespoke': 479,\n",
       " 'beverage': 480,\n",
       " 'bexhill': 481,\n",
       " 'bias': 482,\n",
       " 'biased': 483,\n",
       " 'bid': 484,\n",
       " 'bids': 485,\n",
       " 'big': 486,\n",
       " 'biggest': 487,\n",
       " 'bikes': 488,\n",
       " 'billing': 489,\n",
       " 'billinghay': 490,\n",
       " 'billion': 491,\n",
       " 'bills': 492,\n",
       " 'biology': 493,\n",
       " 'birmingham': 494,\n",
       " 'birthdays': 495,\n",
       " 'bit': 496,\n",
       " 'black': 497,\n",
       " 'blackburn': 498,\n",
       " 'blake': 499,\n",
       " 'blocked': 500,\n",
       " 'blood': 501,\n",
       " 'bls': 502,\n",
       " 'blue': 503,\n",
       " 'bluebird': 504,\n",
       " 'bluechip': 505,\n",
       " 'bluestones': 506,\n",
       " 'bms': 507,\n",
       " 'bmsbmsit': 508,\n",
       " 'bmsgraduates': 509,\n",
       " 'bmsit': 510,\n",
       " 'bmsuk': 511,\n",
       " 'board': 512,\n",
       " 'boast': 513,\n",
       " 'boasts': 514,\n",
       " 'bodies': 515,\n",
       " 'body': 516,\n",
       " 'boiler': 517,\n",
       " 'boilers': 518,\n",
       " 'bolting': 519,\n",
       " 'bonus': 520,\n",
       " 'bonuses': 521,\n",
       " 'book': 522,\n",
       " 'booked': 523,\n",
       " 'booking': 524,\n",
       " 'bookings': 525,\n",
       " 'bookkeeper': 526,\n",
       " 'bookkeeping': 527,\n",
       " 'books': 528,\n",
       " 'boost': 529,\n",
       " 'border': 530,\n",
       " 'boring': 531,\n",
       " 'boss': 532,\n",
       " 'boundaries': 533,\n",
       " 'bournemouth': 534,\n",
       " 'boutique': 535,\n",
       " 'box': 536,\n",
       " 'boxes': 537,\n",
       " 'brace': 538,\n",
       " 'bracknell': 539,\n",
       " 'bradford': 540,\n",
       " 'brain': 541,\n",
       " 'branch': 542,\n",
       " 'branches': 543,\n",
       " 'brand': 544,\n",
       " 'branded': 545,\n",
       " 'brands': 546,\n",
       " 'break': 547,\n",
       " 'breakdown': 548,\n",
       " 'breakdowns': 549,\n",
       " 'breaking': 550,\n",
       " 'breheny': 551,\n",
       " 'brian': 552,\n",
       " 'briant': 553,\n",
       " 'bridge': 554,\n",
       " 'briefing': 555,\n",
       " 'briefings': 556,\n",
       " 'briefs': 557,\n",
       " 'bright': 558,\n",
       " 'brighton': 559,\n",
       " 'brilliant': 560,\n",
       " 'bring': 561,\n",
       " 'bringing': 562,\n",
       " 'brings': 563,\n",
       " 'bristol': 564,\n",
       " 'britain': 565,\n",
       " \"britain's\": 566,\n",
       " 'british': 567,\n",
       " 'brixton': 568,\n",
       " 'broad': 569,\n",
       " 'broaden': 570,\n",
       " 'broken': 571,\n",
       " 'broker': 572,\n",
       " 'brokerage': 573,\n",
       " 'brokers': 574,\n",
       " 'broking': 575,\n",
       " 'bromley': 576,\n",
       " 'broughton': 577,\n",
       " 'brown': 578,\n",
       " 'bsc': 579,\n",
       " 'bubble': 580,\n",
       " 'buckinghamshire': 581,\n",
       " 'buckle': 582,\n",
       " 'budget': 583,\n",
       " 'budgetary': 584,\n",
       " 'budgeted': 585,\n",
       " 'budgeting': 586,\n",
       " 'budgets': 587,\n",
       " 'bug': 588,\n",
       " 'build': 589,\n",
       " 'building': 590,\n",
       " 'buildings': 591,\n",
       " 'builds': 592,\n",
       " 'built': 593,\n",
       " 'bulk': 594,\n",
       " 'bull': 595,\n",
       " 'bullability': 596,\n",
       " 'bupa': 597,\n",
       " 'bureau': 598,\n",
       " 'bureaux': 599,\n",
       " 'burgess': 600,\n",
       " 'burscough': 601,\n",
       " 'bury': 602,\n",
       " 'bus': 603,\n",
       " 'businesses': 604,\n",
       " 'busy': 605,\n",
       " 'butler': 606,\n",
       " 'button': 607,\n",
       " 'buy': 608,\n",
       " 'buyer': 609,\n",
       " 'buyers': 610,\n",
       " 'buying': 611,\n",
       " 'buyside': 612,\n",
       " 'buytolet': 613,\n",
       " 'bydwragedd': 614,\n",
       " 'bydwreigiaeth': 615,\n",
       " 'cable': 616,\n",
       " 'cabling': 617,\n",
       " 'cad': 618,\n",
       " 'cadstar': 619,\n",
       " 'cae': 620,\n",
       " 'calco': 621,\n",
       " 'calculation': 622,\n",
       " 'calculations': 623,\n",
       " 'calculus': 624,\n",
       " 'calibrating': 625,\n",
       " 'calibration': 626,\n",
       " 'calibre': 627,\n",
       " 'california': 628,\n",
       " 'call': 629,\n",
       " 'called': 630,\n",
       " 'caller': 631,\n",
       " 'calling': 632,\n",
       " 'calls': 633,\n",
       " 'calm': 634,\n",
       " 'cam': 635,\n",
       " 'cambridge': 636,\n",
       " 'cambridgeshire': 637,\n",
       " 'cameras': 638,\n",
       " 'camhs': 639,\n",
       " 'campaign': 640,\n",
       " 'campaigns': 641,\n",
       " 'canada': 642,\n",
       " 'cancer': 643,\n",
       " 'candidates': 644,\n",
       " 'cannock': 645,\n",
       " 'canteen': 646,\n",
       " 'canvassing': 647,\n",
       " 'capabilities': 648,\n",
       " 'capability': 649,\n",
       " 'capable': 650,\n",
       " 'capacity': 651,\n",
       " 'capex': 652,\n",
       " 'capita': 653,\n",
       " 'capital': 654,\n",
       " 'capture': 655,\n",
       " 'car': 656,\n",
       " 'carbon': 657,\n",
       " 'carcraft': 658,\n",
       " 'card': 659,\n",
       " 'cardiac': 660,\n",
       " 'cardiff': 661,\n",
       " 'cardiology': 662,\n",
       " 'cards': 663,\n",
       " 'care': 664,\n",
       " 'cared': 665,\n",
       " 'career': 666,\n",
       " 'careers': 667,\n",
       " 'carefully': 668,\n",
       " 'carer': 669,\n",
       " 'carers': 670,\n",
       " 'cares': 671,\n",
       " 'caribbean': 672,\n",
       " 'carillion': 673,\n",
       " 'carillon': 674,\n",
       " 'caring': 675,\n",
       " 'carl': 676,\n",
       " 'caroline': 677,\n",
       " 'carpet': 678,\n",
       " 'carpets': 679,\n",
       " 'carried': 680,\n",
       " 'carrier': 681,\n",
       " 'carriers': 682,\n",
       " 'carries': 683,\n",
       " 'carry': 684,\n",
       " 'carrying': 685,\n",
       " 'cars': 686,\n",
       " 'cart': 687,\n",
       " 'case': 688,\n",
       " 'caseload': 689,\n",
       " 'cases': 690,\n",
       " 'casework': 691,\n",
       " 'cash': 692,\n",
       " 'cashflow': 693,\n",
       " 'cashier': 694,\n",
       " 'cashiering': 695,\n",
       " 'castings': 696,\n",
       " 'casual': 697,\n",
       " 'casualty': 698,\n",
       " 'catalyst': 699,\n",
       " 'categories': 700,\n",
       " 'catering': 701,\n",
       " 'caterpillar': 702,\n",
       " 'caters': 703,\n",
       " 'catia': 704,\n",
       " 'ccab': 705,\n",
       " 'ccn': 706,\n",
       " 'cct': 707,\n",
       " 'cctv': 708,\n",
       " 'cduttoncompassltd': 709,\n",
       " 'celebrating': 710,\n",
       " 'celesio': 711,\n",
       " 'cell': 712,\n",
       " 'cells': 713,\n",
       " 'cellular': 714,\n",
       " 'cemap': 715,\n",
       " 'ceng': 716,\n",
       " 'central': 717,\n",
       " 'centrally': 718,\n",
       " 'centre': 719,\n",
       " \"centre's\": 720,\n",
       " 'centred': 721,\n",
       " 'centres': 722,\n",
       " 'century': 723,\n",
       " 'ceo': 724,\n",
       " 'certificate': 725,\n",
       " 'certificates': 726,\n",
       " 'certification': 727,\n",
       " 'certifications': 728,\n",
       " 'certified': 729,\n",
       " 'certus': 730,\n",
       " 'cfo': 731,\n",
       " 'chain': 732,\n",
       " 'chains': 733,\n",
       " 'chairing': 734,\n",
       " 'challenge': 735,\n",
       " 'challenges': 736,\n",
       " 'challenging': 737,\n",
       " 'champion': 738,\n",
       " 'chance': 739,\n",
       " 'change': 740,\n",
       " 'changed': 741,\n",
       " 'changing': 742,\n",
       " 'channel': 743,\n",
       " 'channels': 744,\n",
       " 'character': 745,\n",
       " 'characteristics': 746,\n",
       " 'charge': 747,\n",
       " 'charged': 748,\n",
       " 'charismatic': 749,\n",
       " 'charitable': 750,\n",
       " 'charities': 751,\n",
       " 'charity': 752,\n",
       " 'chartered': 753,\n",
       " 'charterhouse': 754,\n",
       " 'chartership': 755,\n",
       " 'chase': 756,\n",
       " 'chasemedical': 757,\n",
       " 'chat': 758,\n",
       " 'check': 759,\n",
       " 'checkable': 760,\n",
       " 'checking': 761,\n",
       " 'checks': 762,\n",
       " 'chelmsford': 763,\n",
       " 'cheltenham': 764,\n",
       " 'chemical': 765,\n",
       " 'cheques': 766,\n",
       " 'cheshire': 767,\n",
       " 'chester': 768,\n",
       " 'chesterfield': 769,\n",
       " 'chi': 770,\n",
       " 'chichester': 771,\n",
       " 'chief': 772,\n",
       " 'child': 773,\n",
       " \"child's\": 774,\n",
       " 'childcare': 775,\n",
       " 'children': 776,\n",
       " \"children's\": 777,\n",
       " 'chip': 778,\n",
       " 'choice': 779,\n",
       " 'choices': 780,\n",
       " 'choose': 781,\n",
       " 'chosen': 782,\n",
       " 'chris': 783,\n",
       " 'christmas': 784,\n",
       " 'church': 785,\n",
       " 'chwefror': 786,\n",
       " 'cima': 787,\n",
       " 'cinema': 788,\n",
       " 'circa': 789,\n",
       " 'circuit': 790,\n",
       " 'circuitry': 791,\n",
       " 'circuits': 792,\n",
       " 'circumstances': 793,\n",
       " 'cis': 794,\n",
       " 'cisco': 795,\n",
       " 'citizen': 796,\n",
       " 'citizens': 797,\n",
       " 'city': 798,\n",
       " 'civil': 799,\n",
       " 'civils': 800,\n",
       " 'claims': 801,\n",
       " 'clarity': 802,\n",
       " 'clark': 803,\n",
       " 'class': 804,\n",
       " 'classes': 805,\n",
       " 'classification': 806,\n",
       " 'clean': 807,\n",
       " 'cleaning': 808,\n",
       " 'cleanliness': 809,\n",
       " 'clear': 810,\n",
       " 'clearance': 811,\n",
       " 'cleared': 812,\n",
       " 'clerical': 813,\n",
       " 'clerk': 814,\n",
       " 'click': 815,\n",
       " 'clicking': 816,\n",
       " \"client's\": 817,\n",
       " 'clientfacing': 818,\n",
       " 'climate': 819,\n",
       " 'climb': 820,\n",
       " 'climbing': 821,\n",
       " 'clinic': 822,\n",
       " 'clinical': 823,\n",
       " 'clinicians': 824,\n",
       " 'clinics': 825,\n",
       " 'close': 826,\n",
       " 'closed': 827,\n",
       " 'closely': 828,\n",
       " 'closer': 829,\n",
       " 'closes': 830,\n",
       " 'closing': 831,\n",
       " 'clothing': 832,\n",
       " 'cloud': 833,\n",
       " 'club': 834,\n",
       " 'clustering': 835,\n",
       " 'cmc': 836,\n",
       " 'cmm': 837,\n",
       " \"cmm's\": 838,\n",
       " 'cms': 839,\n",
       " 'cnc': 840,\n",
       " 'coach': 841,\n",
       " 'coaching': 842,\n",
       " 'code': 843,\n",
       " 'coded': 844,\n",
       " 'codes': 845,\n",
       " 'coding': 846,\n",
       " 'coen': 847,\n",
       " 'colchester': 848,\n",
       " 'cold': 849,\n",
       " 'coldcalling': 850,\n",
       " 'collaborating': 851,\n",
       " 'collaboration': 852,\n",
       " 'colleague': 853,\n",
       " 'colleagues': 854,\n",
       " 'collect': 855,\n",
       " 'collected': 856,\n",
       " 'collection': 857,\n",
       " 'collections': 858,\n",
       " 'college': 859,\n",
       " 'colour': 860,\n",
       " 'combat': 861,\n",
       " 'combination': 862,\n",
       " 'combine': 863,\n",
       " 'combined': 864,\n",
       " 'comfort': 865,\n",
       " 'comfortable': 866,\n",
       " 'comforting': 867,\n",
       " 'coming': 868,\n",
       " 'comm': 869,\n",
       " 'command': 870,\n",
       " 'commence': 871,\n",
       " 'commensurate': 872,\n",
       " 'commentary': 873,\n",
       " 'commercial': 874,\n",
       " 'commercially': 875,\n",
       " 'commission': 876,\n",
       " 'commissioning': 877,\n",
       " 'commissions': 878,\n",
       " 'commit': 879,\n",
       " 'commitment': 880,\n",
       " 'commitments': 881,\n",
       " 'committed': 882,\n",
       " 'committee': 883,\n",
       " 'commodities': 884,\n",
       " 'commodity': 885,\n",
       " 'common': 886,\n",
       " 'comms': 887,\n",
       " 'communal': 888,\n",
       " 'communicate': 889,\n",
       " 'communicated': 890,\n",
       " 'communicating': 891,\n",
       " 'communications': 892,\n",
       " 'communicator': 893,\n",
       " 'community': 894,\n",
       " 'commutable': 895,\n",
       " 'commute': 896,\n",
       " 'companies': 897,\n",
       " 'companionship': 898,\n",
       " \"company's\": 899,\n",
       " 'comparable': 900,\n",
       " 'compass': 901,\n",
       " 'compassionate': 902,\n",
       " 'compatibility': 903,\n",
       " 'compelling': 904,\n",
       " 'compensation': 905,\n",
       " 'competence': 906,\n",
       " 'competencies': 907,\n",
       " 'competency': 908,\n",
       " 'competent': 909,\n",
       " 'competently': 910,\n",
       " 'competition': 911,\n",
       " 'competitive': 912,\n",
       " 'competitor': 913,\n",
       " 'competitors': 914,\n",
       " 'compile': 915,\n",
       " 'compiling': 916,\n",
       " 'complaint': 917,\n",
       " 'complaints': 918,\n",
       " 'complement': 919,\n",
       " 'complete': 920,\n",
       " 'completed': 921,\n",
       " 'completely': 922,\n",
       " 'completeness': 923,\n",
       " 'completing': 924,\n",
       " 'completion': 925,\n",
       " 'complex': 926,\n",
       " 'complexity': 927,\n",
       " 'compliance': 928,\n",
       " 'compliant': 929,\n",
       " 'complied': 930,\n",
       " 'complies': 931,\n",
       " 'comply': 932,\n",
       " 'complying': 933,\n",
       " 'component': 934,\n",
       " 'components': 935,\n",
       " 'composite': 936,\n",
       " 'comprehension': 937,\n",
       " 'comprehensive': 938,\n",
       " 'compressed': 939,\n",
       " 'compressors': 940,\n",
       " 'computational': 941,\n",
       " 'computations': 942,\n",
       " 'computer': 943,\n",
       " 'computerised': 944,\n",
       " 'concentrate': 945,\n",
       " 'concentration': 946,\n",
       " 'concept': 947,\n",
       " 'concepts': 948,\n",
       " 'conceptual': 949,\n",
       " 'concern': 950,\n",
       " 'concerned': 951,\n",
       " 'concerns': 952,\n",
       " 'concise': 953,\n",
       " 'conclusion': 954,\n",
       " 'condition': 955,\n",
       " 'conditioning': 956,\n",
       " 'conditions': 957,\n",
       " 'conduct': 958,\n",
       " 'conducted': 959,\n",
       " 'conducting': 960,\n",
       " 'conduit': 961,\n",
       " 'confederation': 962,\n",
       " 'conference': 963,\n",
       " 'conferences': 964,\n",
       " 'confidence': 965,\n",
       " 'confident': 966,\n",
       " 'confidential': 967,\n",
       " 'confidentiality': 968,\n",
       " 'confidently': 969,\n",
       " 'configuration': 970,\n",
       " 'confirm': 971,\n",
       " 'confirmation': 972,\n",
       " 'confirming': 973,\n",
       " 'conflicting': 974,\n",
       " 'conjunction': 975,\n",
       " 'connection': 976,\n",
       " 'connections': 977,\n",
       " 'connectivity': 978,\n",
       " 'conscious': 979,\n",
       " 'consent': 980,\n",
       " 'consenting': 981,\n",
       " 'considerable': 982,\n",
       " 'consideration': 983,\n",
       " 'considered': 984,\n",
       " 'consistency': 985,\n",
       " 'consistent': 986,\n",
       " 'consistently': 987,\n",
       " 'consisting': 988,\n",
       " 'consists': 989,\n",
       " 'consolidated': 990,\n",
       " 'consolidation': 991,\n",
       " 'constant': 992,\n",
       " 'constantly': 993,\n",
       " 'constraints': 994,\n",
       " 'construction': 995,\n",
       " 'constructively': 996,\n",
       " 'consult': 997,\n",
       " 'consultancies': 998,\n",
       " 'consultancy': 999,\n",
       " ...}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_indexed = {word: index for index, word in enumerate(sorted_vocab)} # stores in word_string:word_integer_index format\n",
    "vocab_indexed "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving required outputs\n",
    "Save the vocabulary, bigrams and job advertisment txt as per spectification.\n",
    "- vocab.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to save output data...\n",
    "\n",
    "def save_feature(featFilename,tk_feature):\n",
    "    \"\"\"\n",
    "    Function to save the processed feature data (descripton/title)\n",
    "    \"\"\"\n",
    "    output_file = open(featFilename, 'w') # creates a txt file and open to save the reviews\n",
    "    string = \"\\n\".join([\" \".join(feat) for feat in tk_feature]) # each line each doc\n",
    "    string = string.strip()\n",
    "    output_file.write(string.rstrip())\n",
    "    output_file.close() # close the file\n",
    "    \n",
    "def save_industry(industryFilename,industry):\n",
    "    \"\"\"\n",
    "    Function to save the target data, i.e, industry\n",
    "    \"\"\"\n",
    "    output_file = open(industryFilename, 'w') # creates a txt file and open to save sentiments\n",
    "    string = \"\\n\".join([str(s) for s in industry])\n",
    "    output_file.write(string)\n",
    "    output_file.close() # close the file    \n",
    "\n",
    "\n",
    "def save_vocabulary(vocabFilename,vocab):\n",
    "    \"\"\"\n",
    "    Function to save the generated vocabulary\n",
    "    \"\"\"\n",
    "    with open(vocabFilename, 'w') as file:\n",
    "        for word, index in vocab_indexed.items():\n",
    "            file.write(f\"{word}:{index}\\n\")\n",
    "\n",
    "\n",
    "def save_webindex(windexFileName, windex):\n",
    "    \"\"\"\n",
    "    Function to save the web index, so later we can use it in process of count vector generation\n",
    "    \"\"\"\n",
    "    with open(windexFileName, 'w') as file:\n",
    "        for index in windex:\n",
    "            # print(f\"#{index[2:]}\\n\")\n",
    "            file.write(f\"{index[2:]}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_feature('generated_features/descriptions.txt',tk_descriptions) # save descriptions\n",
    "save_feature('generated_features/titles.txt',tk_title) # save titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_industry('generated_features/industry.txt',jindustry) # save industry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_webindex('generated_features/web_index.txt', windex) # save webindex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our client is looking to recruit an experienced Sales Purchase ledger clerk. You will be covering maternity over from February 2013  mid next year. The ideal candidate would be available immediately. DUTIES AND RESPONSIBILITIES (NOT LIMITED) Sales Ledger To input cheques/ bacs received onto Sage 200 accurately To reconcile remittances with actual receipts. To prepare the banking book To be responsible and ensure that all credit control has been done in a professional and timely manner. To send customer statements on a monthly basis Managing Aged Debtors Report Purchase Ledger To prepare the payment run, ensuring all invoices which are due will be processed and that there are no duplicates. To log all payments onto Sage 200 (cheques, bacs and chaps) To deal with account payable queries Managing Aged Creditors Report SKILLS REQUIREMENTS: 2 years experience Experience of systems and invoicing A good understanding of currencies Computer Literate in office, outlook, word and excel Sage 200 experience preferred, minimum Sage 50 Ability to work to tight deadlines without errors Good numeracy skills Good communication skills Well organised and efficient Good attention to detail This job was originally posted as www.totaljobs.com/JobSeeking/SalesPurchaseLedgerClerkMaternityCover_job****\n",
      "----\n",
      "['recruit', 'experienced', 'purchase', 'ledger', 'clerk', 'covering', 'maternity', 'february', 'mid', 'year', 'ideal', 'immediately', 'duties', 'responsibilities', 'limited', 'ledger', 'input', 'cheques', 'bacs', 'received', 'sage', 'accurately', 'reconcile', 'actual', 'receipts', 'prepare', 'banking', 'book', 'responsible', 'ensure', 'credit', 'control', 'professional', 'timely', 'manner', 'send', 'statements', 'monthly', 'basis', 'managing', 'aged', 'debtors', 'report', 'purchase', 'ledger', 'prepare', 'payment', 'run', 'ensuring', 'invoices', 'due', 'processed', 'log', 'payments', 'sage', 'cheques', 'bacs', 'deal', 'account', 'payable', 'queries', 'managing', 'aged', 'creditors', 'report', 'requirements', 'years', 'systems', 'invoicing', 'understanding', 'computer', 'literate', 'office', 'outlook', 'word', 'excel', 'sage', 'preferred', 'minimum', 'sage', 'tight', 'deadlines', 'errors', 'numeracy', 'organised', 'efficient', 'attention', 'detail', 'totaljobs']\n",
      "----\n",
      ": 68684698\n"
     ]
    }
   ],
   "source": [
    "print(descp[ind]) # an example of a description txt\n",
    "print(\"----\")\n",
    "print(tk_descriptions[ind]) \n",
    "print(\"----\")\n",
    "print(windex[ind]) # 68684698"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! They are stored without mismatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all(job_data.target==jindustry) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(776, 776, 776)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tk_descriptions),len(jindustry),len(windex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving vocabulary\n",
    "save_vocabulary('generated_features/vocab.txt',save_vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "This text preprocessing task has been a valuable learning experience. It emphasized the importance of meticulous data cleaning in natural language processing. Key takeaways include tokenization, lowercasing, stop word removal, and filtering rare and common terms based on term frequency and document frequency respectively. These steps are critical for enhancing data quality and preparing it for downstream NLP tasks. Additionally, creating a vocabulary aids in understanding the dataset's unique terms. Overall, this task underscores that proper preprocessing is a fundamental aspect of text analysis, enabling more accurate and insightful results in machine learning and NLP applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acknowledgements\n",
    "\n",
    "Some of the code (functions) are used (with modification) from weekly (week 7 to week 9) activity notebooks and lab notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "[1]The Coding Train, 12.2: Color Vectors - Programming with Text, www.youtube.com, Oct. 21, 2018. https://www.youtube.com/watch?v=mI23bDF0VRI (accessed Sep. 30, 2023).\n",
    "\n",
    "[2]aparrish, Understanding Word Vectors, GitHub Gist. https://gist.github.com/aparrish/2f562e3737544cf29aaf1af30362f469 (accessed Sep. 30, 2023).\n",
    "\n",
    "[3] Week7, Week8, Week9 codes and ideas from both activity and lab materials"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
